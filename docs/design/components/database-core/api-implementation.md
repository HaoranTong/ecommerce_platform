<!--
æ–‡æ¡£è¯´æ˜ï¼š
- å†…å®¹ï¼šæ•°æ®åº“æ ¸å¿ƒæ¨¡å—APIæ¥å£å®ç°ç»†èŠ‚ï¼ŒåŒ…å«SQLAlchemyè¿æ¥æ± ç®¡ç†çš„å…·ä½“å®ç°
- ä½¿ç”¨æ–¹æ³•ï¼šå¼€å‘äººå‘˜å®ç°æ•°æ®åº“è¿æ¥åŠŸèƒ½æ—¶çš„è¯¦ç»†æŒ‡å¯¼æ–‡æ¡£
- æ›´æ–°æ–¹æ³•ï¼šæ•°æ®åº“å®ç°ä»£ç å˜æ›´æ—¶åŒæ­¥æ›´æ–°ï¼Œè®°å½•å®é™…çš„å®ç°æ–¹æ¡ˆ
- å¼•ç”¨å…³ç³»ï¼šåŸºäºapi-spec.mdæ¥å£è§„èŒƒï¼Œè¢«æ•°æ®è®¿é—®å±‚å¼€å‘ä½¿ç”¨
- æ›´æ–°é¢‘ç‡ï¼šæ•°æ®åº“ä»£ç å®ç°å˜æ›´æ—¶
-->

# æ•°æ®åº“æ ¸å¿ƒæ¨¡å—APIå®ç°ç»†èŠ‚

ğŸ“ **çŠ¶æ€**: âœ… å·²å‘å¸ƒ  
ğŸ“… **åˆ›å»ºæ—¥æœŸ**: 2025-09-13  
ğŸ‘¤ **è´Ÿè´£äºº**: ç³»ç»Ÿæ¶æ„å¸ˆ  
ğŸ”„ **æœ€åæ›´æ–°**: 2025-09-13  
ğŸ“‹ **ç‰ˆæœ¬**: v1.0.0  

## å®ç°æ¶æ„

### æ ¸å¿ƒæ–‡ä»¶ç»“æ„
```
app/database/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ connection.py           # æ•°æ®åº“è¿æ¥ç®¡ç†
â”œâ”€â”€ session.py             # ä¼šè¯ç®¡ç†
â”œâ”€â”€ transaction.py         # äº‹åŠ¡å¤„ç†
â”œâ”€â”€ monitoring.py          # æ•°æ®åº“ç›‘æ§
â””â”€â”€ migrations/
    â”œâ”€â”€ __init__.py
    â””â”€â”€ versions/           # Alembicè¿ç§»æ–‡ä»¶
```

## æ ¸å¿ƒå®ç°

### 1. æ•°æ®åº“è¿æ¥ç®¡ç†

#### æ–‡ä»¶: `app/database/connection.py`
```python
from sqlalchemy import create_engine, event
from sqlalchemy.pool import QueuePool
from sqlalchemy.engine import Engine
from app.core.config import get_settings
import logging
import time

logger = logging.getLogger(__name__)

class DatabaseManager:
    def __init__(self):
        self.engine = None
        self.settings = get_settings()
        self._connection_stats = {
            'total_queries': 0,
            'slow_queries': [],
            'error_count': 0,
            'start_time': time.time()
        }
    
    def create_engine(self) -> Engine:
        """åˆ›å»ºæ•°æ®åº“å¼•æ“"""
        database_url = self.settings.database_url
        
        engine = create_engine(
            database_url,
            poolclass=QueuePool,
            pool_size=10,
            max_overflow=5,
            pool_pre_ping=True,
            pool_recycle=3600,
            echo=self.settings.debug,
            future=True
        )
        
        # æ³¨å†Œäº‹ä»¶ç›‘å¬å™¨
        self._register_event_listeners(engine)
        
        self.engine = engine
        return engine
    
    def _register_event_listeners(self, engine: Engine):
        """æ³¨å†Œæ•°æ®åº“äº‹ä»¶ç›‘å¬å™¨"""
        
        @event.listens_for(engine, "before_cursor_execute")
        def before_cursor_execute(conn, cursor, statement, parameters, context, executemany):
            context._query_start_time = time.time()
        
        @event.listens_for(engine, "after_cursor_execute")
        def after_cursor_execute(conn, cursor, statement, parameters, context, executemany):
            total_time = time.time() - context._query_start_time
            
            # ç»Ÿè®¡æŸ¥è¯¢æ¬¡æ•°
            self._connection_stats['total_queries'] += 1
            
            # è®°å½•æ…¢æŸ¥è¯¢ï¼ˆè¶…è¿‡100msï¼‰
            if total_time > 0.1:
                self._connection_stats['slow_queries'].append({
                    'query': statement[:200] + '...' if len(statement) > 200 else statement,
                    'duration': round(total_time * 1000, 2),
                    'timestamp': time.time()
                })
                
                # åªä¿ç•™æœ€è¿‘50æ¡æ…¢æŸ¥è¯¢
                if len(self._connection_stats['slow_queries']) > 50:
                    self._connection_stats['slow_queries'].pop(0)
        
        @event.listens_for(engine, "handle_error")
        def handle_error(exception_context):
            self._connection_stats['error_count'] += 1
            logger.error(f"æ•°æ®åº“é”™è¯¯: {exception_context.original_exception}")
    
    def get_connection_status(self) -> dict:
        """è·å–è¿æ¥çŠ¶æ€"""
        if not self.engine:
            return {"status": "not_initialized"}
        
        pool = self.engine.pool
        
        return {
            "status": "healthy",
            "connection_pool": {
                "total_connections": pool.size(),
                "active_connections": pool.checkedout(),
                "idle_connections": pool.checkedin(),
                "pool_size": pool.size(),
                "max_overflow": pool._max_overflow
            },
            "performance": {
                "avg_query_time": self._calculate_avg_query_time(),
                "slow_queries": len(self._connection_stats['slow_queries']),
                "total_queries": self._connection_stats['total_queries'],
                "error_count": self._connection_stats['error_count']
            }
        }
    
    def get_performance_metrics(self, time_range: str = "1h") -> dict:
        """è·å–æ€§èƒ½æŒ‡æ ‡"""
        return {
            "time_range": time_range,
            "metrics": {
                "query_count": self._connection_stats['total_queries'],
                "avg_response_time": self._calculate_avg_query_time(),
                "max_response_time": max(
                    [q['duration'] for q in self._connection_stats['slow_queries']], 
                    default=0
                ),
                "error_count": self._connection_stats['error_count'],
                "cache_hit_rate": 85.2  # ç¤ºä¾‹å€¼ï¼Œå®é™…éœ€è¦ä»æ•°æ®åº“è·å–
            },
            "slow_queries": self._connection_stats['slow_queries'][-10:]  # æœ€è¿‘10æ¡
        }
    
    def _calculate_avg_query_time(self) -> float:
        """è®¡ç®—å¹³å‡æŸ¥è¯¢æ—¶é—´"""
        if not self._connection_stats['slow_queries']:
            return 0.0
        
        total_time = sum(q['duration'] for q in self._connection_stats['slow_queries'])
        return round(total_time / len(self._connection_stats['slow_queries']), 2)
    
    def refresh_connection_pool(self) -> dict:
        """åˆ·æ–°è¿æ¥æ± """
        if not self.engine:
            raise Exception("æ•°æ®åº“å¼•æ“æœªåˆå§‹åŒ–")
        
        old_connections = self.engine.pool.checkedout() + self.engine.pool.checkedin()
        
        # é‡æ–°åˆ›å»ºè¿æ¥æ± 
        self.engine.dispose()
        self.engine = self.create_engine()
        
        new_connections = self.engine.pool.size()
        
        return {
            "refresh_time": time.time(),
            "old_connections": old_connections,
            "new_connections": new_connections
        }

# å…¨å±€æ•°æ®åº“ç®¡ç†å™¨å®ä¾‹
db_manager = DatabaseManager()

def get_db_engine() -> Engine:
    """è·å–æ•°æ®åº“å¼•æ“"""
    if db_manager.engine is None:
        db_manager.create_engine()
    return db_manager.engine

async def init_database():
    """åˆå§‹åŒ–æ•°æ®åº“è¿æ¥"""
    logger.info("åˆå§‹åŒ–æ•°æ®åº“è¿æ¥...")
    engine = get_db_engine()
    
    # æµ‹è¯•è¿æ¥
    with engine.connect() as conn:
        conn.execute("SELECT 1")
    
    logger.info("æ•°æ®åº“è¿æ¥åˆå§‹åŒ–å®Œæˆ")

async def close_database():
    """å…³é—­æ•°æ®åº“è¿æ¥"""
    if db_manager.engine:
        db_manager.engine.dispose()
        logger.info("æ•°æ®åº“è¿æ¥å·²å…³é—­")
```

### 2. APIè·¯ç”±å®ç°

#### æ–‡ä»¶: `app/api/database_routes.py`
```python
from fastapi import APIRouter, HTTPException, Depends, Query
from app.core.auth import get_admin_user
from app.database.connection import db_manager
from app.database.migrations import migration_manager
import logging

router = APIRouter(prefix="/api/v1/database", tags=["æ•°æ®åº“ç®¡ç†"])
logger = logging.getLogger(__name__)

@router.get("/status")
async def get_database_status(admin_user=Depends(get_admin_user)):
    """è·å–æ•°æ®åº“è¿æ¥çŠ¶æ€"""
    try:
        status = db_manager.get_connection_status()
        return {
            "success": True,
            "data": status
        }
    except Exception as e:
        logger.error(f"è·å–æ•°æ®åº“çŠ¶æ€å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail="è·å–æ•°æ®åº“çŠ¶æ€å¤±è´¥")

@router.get("/metrics")
async def get_database_metrics(
    time_range: str = Query("1h", regex="^(1h|24h|7d)$"),
    admin_user=Depends(get_admin_user)
):
    """è·å–æ•°æ®åº“æ€§èƒ½æŒ‡æ ‡"""
    try:
        metrics = db_manager.get_performance_metrics(time_range)
        return {
            "success": True,
            "data": metrics
        }
    except Exception as e:
        logger.error(f"è·å–æ•°æ®åº“æ€§èƒ½æŒ‡æ ‡å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail="è·å–æ€§èƒ½æŒ‡æ ‡å¤±è´¥")

@router.post("/pool/refresh")
async def refresh_connection_pool(admin_user=Depends(get_admin_user)):
    """åˆ·æ–°æ•°æ®åº“è¿æ¥æ± """
    try:
        result = db_manager.refresh_connection_pool()
        return {
            "success": True,
            "message": "è¿æ¥æ± åˆ·æ–°æˆåŠŸ",
            "data": result
        }
    except Exception as e:
        logger.error(f"åˆ·æ–°è¿æ¥æ± å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail="åˆ·æ–°è¿æ¥æ± å¤±è´¥")

@router.get("/migrations")
async def get_migration_status(admin_user=Depends(get_admin_user)):
    """è·å–æ•°æ®åº“è¿ç§»çŠ¶æ€"""
    try:
        status = migration_manager.get_migration_status()
        return {
            "success": True,
            "data": status
        }
    except Exception as e:
        logger.error(f"è·å–è¿ç§»çŠ¶æ€å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail="è·å–è¿ç§»çŠ¶æ€å¤±è´¥")
```

### 3. ä¼šè¯ç®¡ç†

#### æ–‡ä»¶: `app/database/session.py`
```python
from sqlalchemy.orm import sessionmaker, Session
from contextlib import contextmanager
from app.database.connection import get_db_engine
import logging

logger = logging.getLogger(__name__)

# åˆ›å»ºä¼šè¯å·¥å‚
SessionLocal = sessionmaker(autocommit=False, autoflush=False)

def get_db_session() -> Session:
    """è·å–æ•°æ®åº“ä¼šè¯"""
    engine = get_db_engine()
    SessionLocal.configure(bind=engine)
    return SessionLocal()

@contextmanager
def get_db_transaction():
    """æ•°æ®åº“äº‹åŠ¡ä¸Šä¸‹æ–‡ç®¡ç†å™¨"""
    session = get_db_session()
    try:
        yield session
        session.commit()
    except Exception as e:
        session.rollback()
        logger.error(f"æ•°æ®åº“äº‹åŠ¡å›æ»š: {e}")
        raise
    finally:
        session.close()

async def get_async_db_session():
    """å¼‚æ­¥è·å–æ•°æ®åº“ä¼šè¯ï¼ˆç”¨äºFastAPIä¾èµ–æ³¨å…¥ï¼‰"""
    session = get_db_session()
    try:
        yield session
    finally:
        session.close()
```

## é…ç½®å’Œä¼˜åŒ–

### æ•°æ®åº“é…ç½®ä¼˜åŒ–
```python
# app/core/config.py ä¸­çš„æ•°æ®åº“é…ç½®
class Settings:
    # æ•°æ®åº“è¿æ¥é…ç½®
    database_url: str = "mysql+pymysql://user:password@localhost/ecommerce"
    
    # è¿æ¥æ± é…ç½®
    db_pool_size: int = 10          # è¿æ¥æ± å¤§å°
    db_max_overflow: int = 5        # æœ€å¤§æº¢å‡ºè¿æ¥æ•°
    db_pool_timeout: int = 30       # è¿æ¥è¶…æ—¶æ—¶é—´
    db_pool_recycle: int = 3600     # è¿æ¥å›æ”¶æ—¶é—´ï¼ˆç§’ï¼‰
    
    # æŸ¥è¯¢ä¼˜åŒ–é…ç½®
    db_echo: bool = False           # æ˜¯å¦è¾“å‡ºSQLæ—¥å¿—
    db_echo_pool: bool = False      # æ˜¯å¦è¾“å‡ºè¿æ¥æ± æ—¥å¿—
```

### ç›‘æ§é›†æˆ
```python
# é›†æˆPrometheusç›‘æ§
from prometheus_client import Counter, Histogram, Gauge

# å®šä¹‰ç›‘æ§æŒ‡æ ‡
db_query_counter = Counter('database_queries_total', 'Database queries')
db_query_duration = Histogram('database_query_duration_seconds', 'Query duration')
db_connections_gauge = Gauge('database_connections_active', 'Active connections')

# åœ¨connection.pyä¸­ä½¿ç”¨
@event.listens_for(engine, "after_cursor_execute")
def after_cursor_execute(conn, cursor, statement, parameters, context, executemany):
    db_query_counter.inc()
    duration = time.time() - context._query_start_time
    db_query_duration.observe(duration)
```
