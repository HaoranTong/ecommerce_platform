#!/usr/bin/env python3#!/usr/bin/env python3

""""""

äº”å±‚æ¶æ„æ™ºèƒ½æµ‹è¯•ç”Ÿæˆå™¨ - å¢å¼ºç‰ˆ v2.0äº”å±‚æ¶æ„æ ‡å‡†æµ‹è¯•ç”Ÿæˆå™¨



æ ¹æ®MASTER.mdè§„èŒƒå’Œtesting-standards.mdç”Ÿæˆå®Œæ•´æµ‹è¯•å¥—ä»¶æ ¹æ®æµ‹è¯•æ ‡å‡† (docs/standards/testing-standards.md) ç”Ÿæˆå®Œæ•´æµ‹è¯•å¥—ä»¶

é›†æˆæ™ºèƒ½æ¨¡å‹åˆ†æå™¨ï¼Œè‡ªåŠ¨è§£æSQLAlchemyæ¨¡å‹ç»“æ„ç¬¦åˆ70%å•å…ƒã€20%é›†æˆã€6%E2Eã€2%çƒŸé›¾ã€2%ä¸“é¡¹çš„åˆ†å±‚æ¶æ„

ç¬¦åˆ70%å•å…ƒã€20%é›†æˆã€6%E2Eã€2%çƒŸé›¾ã€2%ä¸“é¡¹çš„åˆ†å±‚æ¶æ„

ä½¿ç”¨æ–¹æ³•:

æ ¸å¿ƒåŠŸèƒ½ [CHECK:DEV-009]:    python scripts/generate_test_template.py module_name [--type all|unit|integration|smoke|e2e|specialized]

1. AST+è¿è¡Œæ—¶åŒé‡æ¨¡å‹åˆ†æ    

2. æ™ºèƒ½Factory Boyå·¥å‚ç”Ÿæˆç¤ºä¾‹:

3. å®Œæ•´äº”å±‚æµ‹è¯•æ¶æ„ç”Ÿæˆ    python scripts/generate_test_template.py user_auth --type all

4. è‡ªåŠ¨éªŒè¯å’Œè´¨é‡æ£€æŸ¥    python scripts/generate_test_template.py shopping_cart --type unit



ä½¿ç”¨æ–¹æ³•:ç”Ÿæˆæ ‡å‡†:

    python scripts/generate_test_template.py module_name [options]- Factory Boyæ•°æ®å·¥å‚æ¨¡å¼

    - pytest.inié…ç½®è¦æ±‚  

ç¤ºä¾‹:- äº”å±‚æµ‹è¯•æ¶æ„åˆ†å¸ƒ

    python scripts/generate_test_template.py user_auth --type all --validate- æ ‡å‡†åŒ–æµ‹è¯•ç»“æ„

    python scripts/generate_test_template.py shopping_cart --type unit --dry-run"""

    

å‚æ•°è¯´æ˜:import sys

    --type TYPE        : æµ‹è¯•ç±»å‹ (all|unit|integration|smoke|e2e|specialized)import os

    --validate        : ç”Ÿæˆåè‡ªåŠ¨éªŒè¯æµ‹è¯•æ–‡ä»¶import argparse

    --dry-run         : ä»…åˆ†ææ¨¡å‹ï¼Œä¸ç”Ÿæˆæ–‡ä»¶from pathlib import Path

    --detailed        : è¾“å‡ºè¯¦ç»†åˆ†ææŠ¥å‘Šfrom datetime import datetime

    --force           : å¼ºåˆ¶è¦†ç›–existing filesfrom typing import Dict, List, Any, Optional, Tuple

    from dataclasses import dataclass

ç¬¦åˆæ ‡å‡†:import ast

- MASTER.mdå¼ºåˆ¶æ£€æŸ¥ç‚¹è§„èŒƒ [CHECK:DEV-009] [CHECK:TEST-001]import inspect

- testing-standards.mdäº”å±‚æ¶æ„import importlib.util

- Factory Boyæ•°æ®å·¥å‚æ¨¡å¼

- pytest.inié…ç½®è¦æ±‚# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„

"""project_root = Path(__file__).parent.parent

sys.path.insert(0, str(project_root))

import sys

import os

import argparse@dataclass

import astclass FieldInfo:

import inspect    """å­—æ®µä¿¡æ¯æ•°æ®ç±»"""

import importlib.util    name: str

import subprocess    column_type: str

import json    python_type: str

from pathlib import Path    nullable: bool

from datetime import datetime    primary_key: bool

from typing import Dict, List, Any, Optional, Tuple, Union    foreign_key: Optional[str]

from dataclasses import dataclass, field    unique: bool

    default: Any

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„    constraints: List[str]

project_root = Path(__file__).parent.parent    

sys.path.insert(0, str(project_root))    

@dataclass  

class RelationshipInfo:

@dataclass    """å…³ç³»ä¿¡æ¯æ•°æ®ç±»"""

class FieldInfo:    name: str

    """å­—æ®µä¿¡æ¯æ•°æ®ç±» - å®Œæ•´å­—æ®µå…ƒæ•°æ®"""    related_model: str

    name: str    relationship_type: str  # one-to-one, one-to-many, many-to-many

    column_type: str    back_populates: Optional[str]

    python_type: str    cascade: Optional[str]

    nullable: bool    foreign_keys: List[str]

    primary_key: bool

    foreign_key: Optional[str]

    unique: bool@dataclass

    default: Anyclass ModelInfo:

    constraints: List[str] = field(default_factory=list)    """æ¨¡å‹ä¿¡æ¯æ•°æ®ç±»"""

    max_length: Optional[int] = None    name: str

    index: bool = False    tablename: str

    server_default: Any = None    fields: List[FieldInfo]

        relationships: List[RelationshipInfo]

        mixins: List[str]

@dataclass      docstring: Optional[str]

class RelationshipInfo:    primary_keys: List[str]

    """å…³ç³»ä¿¡æ¯æ•°æ®ç±» - å®Œæ•´å…³ç³»å…ƒæ•°æ®"""    unique_constraints: List[List[str]]

    name: str

    related_model: str

    relationship_type: str  # one-to-one, one-to-many, many-to-manyclass FiveLayerTestGenerator:

    back_populates: Optional[str]    """äº”å±‚æ¶æ„æµ‹è¯•ç”Ÿæˆå™¨ - é›†æˆæ™ºèƒ½æ¨¡å‹åˆ†æ [CHECK:DEV-009]"""

    cascade: Optional[str]    

    foreign_keys: List[str] = field(default_factory=list)    def __init__(self):

    secondary: Optional[str] = None        self.project_root = Path(__file__).parent.parent

    lazy: Optional[str] = None        self.test_distributions = {

            'unit': 0.70,      # 70% å•å…ƒæµ‹è¯•

            'integration': 0.20, # 20% é›†æˆæµ‹è¯•  

@dataclass            'e2e': 0.06,       # 6% E2Eæµ‹è¯•

class ModelInfo:            'smoke': 0.02,     # 2% çƒŸé›¾æµ‹è¯•

    """æ¨¡å‹ä¿¡æ¯æ•°æ®ç±» - å®Œæ•´æ¨¡å‹å…ƒæ•°æ®"""            'specialized': 0.02 # 2% ä¸“é¡¹æµ‹è¯•

    name: str        }

    tablename: str        self.models_cache = {}

    fields: List[FieldInfo]    

    relationships: List[RelationshipInfo]    def analyze_module_models(self, module_name: str) -> Dict[str, ModelInfo]:

    mixins: List[str] = field(default_factory=list)        """æ™ºèƒ½åˆ†ææ¨¡å—ä¸­çš„æ‰€æœ‰æ•°æ®æ¨¡å‹ [CHECK:TEST-001]"""

    docstring: Optional[str] = None        if module_name in self.models_cache:

    primary_keys: List[str] = field(default_factory=list)            return self.models_cache[module_name]

    unique_constraints: List[List[str]] = field(default_factory=list)            

    indexes: List[str] = field(default_factory=list)        print(f"ğŸ” æ™ºèƒ½åˆ†ææ¨¡å—: {module_name}")

            

    @property        # 1. å®šä½æ¨¡å—æ–‡ä»¶

    def foreign_key_fields(self) -> List[FieldInfo]:        models_file = self.project_root / f"app/modules/{module_name}/models.py"

        """è·å–æ‰€æœ‰å¤–é”®å­—æ®µ"""        if not models_file.exists():

        return [f for f in self.fields if f.foreign_key]            raise FileNotFoundError(f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {models_file}")

                

    @property        # 2. ASTè¯­æ³•åˆ†æ

    def unique_fields(self) -> List[FieldInfo]:        ast_models = self._analyze_ast(models_file)

        """è·å–æ‰€æœ‰å”¯ä¸€å­—æ®µ"""        print(f"ğŸ“‹ ASTåˆ†æå‘ç° {len(ast_models)} ä¸ªæ¨¡å‹ç±»")

        return [f for f in self.fields if f.unique]        

                # 3. è¿è¡Œæ—¶åˆ†æï¼ˆå¯¼å…¥æ¨¡å—è·å–å®Œæ•´ä¿¡æ¯ï¼‰

    @property        runtime_models = self._analyze_runtime(module_name)

    def required_fields(self) -> List[FieldInfo]:        print(f"ğŸƒ è¿è¡Œæ—¶åˆ†æå‘ç° {len(runtime_models)} ä¸ªæ¨¡å‹ç±»")

        """è·å–æ‰€æœ‰å¿…å¡«å­—æ®µ"""        

        return [f for f in self.fields if not f.nullable and not f.primary_key and f.default is None]        # 4. åˆå¹¶åˆ†æç»“æœ

        merged_models = self._merge_analysis_results(ast_models, runtime_models)

        print(f"âœ… åˆå¹¶å®Œæˆï¼Œå…±åˆ†æ {len(merged_models)} ä¸ªæ¨¡å‹")

class IntelligentModelAnalyzer:        

    """æ™ºèƒ½æ¨¡å‹åˆ†æå™¨ - AST+è¿è¡Œæ—¶åŒé‡åˆ†æ [CHECK:TEST-001]"""        # 5. ç¼“å­˜ç»“æœ

            self.models_cache[module_name] = merged_models

    def __init__(self, project_root: Path):        return merged_models

        self.project_root = project_root        

        self.analysis_cache = {}    def _analyze_ast(self, models_file: Path) -> Dict[str, Dict]:

                """ASTè¯­æ³•åˆ†æ - è·å–æºä»£ç ç»“æ„"""

    def analyze_module(self, module_name: str) -> Dict[str, ModelInfo]:        with open(models_file, 'r', encoding='utf-8') as f:

        """å®Œæ•´åˆ†ææ¨¡å—ä¸­çš„æ‰€æœ‰æ•°æ®æ¨¡å‹"""            content = f.read()

        if module_name in self.analysis_cache:            

            return self.analysis_cache[module_name]        tree = ast.parse(content)

                    models = {}

        print(f"ğŸ” æ™ºèƒ½åˆ†ææ¨¡å—: {module_name}")        

                for node in ast.walk(tree):

        # 1. éªŒè¯æ¨¡å—æ–‡ä»¶å­˜åœ¨            if isinstance(node, ast.ClassDef):

        models_file = self.project_root / f"app/modules/{module_name}/models.py"                # æ£€æŸ¥æ˜¯å¦æ˜¯SQLAlchemyæ¨¡å‹ç±»

        if not models_file.exists():                if self._is_sqlalchemy_model(node):

            raise FileNotFoundError(f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {models_file}")                    model_info = self._extract_model_info_from_ast(node)

                                models[node.name] = model_info

        # 2. ASTè¯­æ³•åˆ†æ - è·å–æºä»£ç ç»“æ„                    

        print("ğŸ“‹ æ‰§è¡ŒASTè¯­æ³•åˆ†æ...")        return models

        ast_models = self._analyze_ast(models_file)        

        print(f"   å‘ç° {len(ast_models)} ä¸ªæ¨¡å‹ç±»")    def _is_sqlalchemy_model(self, class_node: ast.ClassDef) -> bool:

                """æ£€æŸ¥ç±»æ˜¯å¦æ˜¯SQLAlchemyæ¨¡å‹"""

        # 3. è¿è¡Œæ—¶åˆ†æ - è·å–å®Œæ•´ç±»ä¿¡æ¯        # æ£€æŸ¥æ˜¯å¦ç»§æ‰¿è‡ªBaseæˆ–åŒ…å«__tablename__

        print("ğŸƒ æ‰§è¡Œè¿è¡Œæ—¶åˆ†æ...")        for base in class_node.bases:

        runtime_models = self._analyze_runtime(module_name)            if isinstance(base, ast.Name) and base.id == 'Base':

        print(f"   åˆ†æ {len(runtime_models)} ä¸ªæ¨¡å‹ç±»")                return True

                        

        # 4. åˆå¹¶å’ŒéªŒè¯åˆ†æç»“æœ        # æ£€æŸ¥æ˜¯å¦æœ‰__tablename__å±æ€§

        print("ğŸ”— åˆå¹¶åˆ†æç»“æœ...")        for item in class_node.body:

        merged_models = self._merge_analysis_results(ast_models, runtime_models)            if (isinstance(item, ast.Assign) and 

                        any(isinstance(target, ast.Name) and target.id == '__tablename__' 

        # 5. éªŒè¯åˆ†æå®Œæ•´æ€§                    for target in item.targets)):

        self._validate_analysis_results(merged_models)                return True

                            

        # 6. ç¼“å­˜ç»“æœ        return False

        self.analysis_cache[module_name] = merged_models        

        print(f"âœ… æ¨¡å‹åˆ†æå®Œæˆï¼Œå…± {len(merged_models)} ä¸ªæ¨¡å‹")    def _extract_model_info_from_ast(self, class_node: ast.ClassDef) -> Dict:

                """ä»ASTèŠ‚ç‚¹æå–æ¨¡å‹ä¿¡æ¯"""

        return merged_models        model_info = {

                    'name': class_node.name,

    def _analyze_ast(self, models_file: Path) -> Dict[str, Dict]:            'tablename': None,

        """ASTè¯­æ³•åˆ†æ - æå–æºä»£ç ç»“æ„ä¿¡æ¯"""            'fields': [],

        with open(models_file, 'r', encoding='utf-8') as f:            'relationships': [],

            content = f.read()            'mixins': [],

                        'docstring': ast.get_docstring(class_node)

        try:        }

            tree = ast.parse(content)        

        except SyntaxError as e:        # æå–åŸºç±»(æ··å…¥)

            raise SyntaxError(f"æ¨¡å‹æ–‡ä»¶è¯­æ³•é”™è¯¯: {e}")        for base in class_node.bases:

                        if isinstance(base, ast.Name):

        models = {}                model_info['mixins'].append(base.id)

                        

        for node in ast.walk(tree):        # åˆ†æç±»ä½“å†…å®¹

            if isinstance(node, ast.ClassDef):        for item in class_node.body:

                if self._is_sqlalchemy_model(node):            if isinstance(item, ast.Assign):

                    model_info = self._extract_model_info_from_ast(node)                self._analyze_assignment(item, model_info)

                    models[node.name] = model_info                

                            return model_info

        return models        

            def _analyze_assignment(self, assign_node: ast.Assign, model_info: Dict):

    def _is_sqlalchemy_model(self, class_node: ast.ClassDef) -> bool:        """åˆ†æèµ‹å€¼è¯­å¥ - æå–å­—æ®µå’Œå…³ç³»å®šä¹‰"""

        """æ£€æŸ¥ç±»æ˜¯å¦æ˜¯SQLAlchemyæ¨¡å‹"""        for target in assign_node.targets:

        # æ£€æŸ¥ç»§æ‰¿å…³ç³» - ç»§æ‰¿è‡ªBase            if isinstance(target, ast.Name):

        for base in class_node.bases:                attr_name = target.id

            if isinstance(base, ast.Name) and base.id == 'Base':                

                return True                if attr_name == '__tablename__':

                                    # æå–è¡¨å

        # æ£€æŸ¥__tablename__å±æ€§å­˜åœ¨                    if isinstance(assign_node.value, ast.Constant):

        for item in class_node.body:                        model_info['tablename'] = assign_node.value.value

            if (isinstance(item, ast.Assign) and                         

                any(isinstance(target, ast.Name) and target.id == '__tablename__'                 elif isinstance(assign_node.value, ast.Call):

                    for target in item.targets)):                    # åˆ†æå‡½æ•°è°ƒç”¨ - Columnæˆ–relationship

                return True                    func_name = self._get_function_name(assign_node.value.func)

                                        

        return False                    if func_name == 'Column':

                                field_info = self._analyze_column_definition(attr_name, assign_node.value)

    def _extract_model_info_from_ast(self, class_node: ast.ClassDef) -> Dict:                        model_info['fields'].append(field_info)

        """ä»ASTèŠ‚ç‚¹æå–æ¨¡å‹åŸºç¡€ä¿¡æ¯"""                        

        model_info = {                    elif func_name == 'relationship':

            'name': class_node.name,                        rel_info = self._analyze_relationship_definition(attr_name, assign_node.value)

            'tablename': None,                        model_info['relationships'].append(rel_info)

            'fields': [],                        

            'relationships': [],    def _get_function_name(self, func_node) -> str:

            'mixins': [],        """è·å–å‡½æ•°åç§°"""

            'docstring': ast.get_docstring(class_node),        if isinstance(func_node, ast.Name):

            'raw_fields': {},  # åŸå§‹å­—æ®µå®šä¹‰ï¼Œä¾›åç»­åˆ†æä½¿ç”¨            return func_node.id

            'raw_relationships': {}  # åŸå§‹å…³ç³»å®šä¹‰        elif isinstance(func_node, ast.Attribute):

        }            return func_node.attr

                return ''

        # æå–åŸºç±»ä¿¡æ¯        

        for base in class_node.bases:    def _analyze_column_definition(self, field_name: str, call_node: ast.Call) -> Dict:

            if isinstance(base, ast.Name):        """åˆ†æColumnå®šä¹‰"""

                model_info['mixins'].append(base.id)        field_info = {

                    'name': field_name,

        # åˆ†æç±»ä½“ - æå–å­—æ®µå’Œå…³ç³»å®šä¹‰            'column_type': None,

        for item in class_node.body:            'nullable': True,  # SQLAlchemyé»˜è®¤

            if isinstance(item, ast.Assign):            'primary_key': False,

                self._analyze_class_assignment(item, model_info)            'foreign_key': None,

                            'unique': False,

        return model_info            'default': None,

                    'constraints': []

    def _analyze_class_assignment(self, assign_node: ast.Assign, model_info: Dict):        }

        """åˆ†æç±»ä¸­çš„èµ‹å€¼è¯­å¥"""        

        for target in assign_node.targets:        # åˆ†æä½ç½®å‚æ•° - é€šå¸¸ç¬¬ä¸€ä¸ªæ˜¯ç±»å‹

            if isinstance(target, ast.Name):        if call_node.args:

                attr_name = target.id            type_arg = call_node.args[0]

                            field_info['column_type'] = self._extract_column_type(type_arg)

                # æå–__tablename__            

                if attr_name == '__tablename__':        # åˆ†æå…³é”®å­—å‚æ•°

                    if isinstance(assign_node.value, ast.Constant):        for keyword in call_node.keywords:

                        model_info['tablename'] = assign_node.value.value            if keyword.arg == 'nullable':

                                        field_info['nullable'] = self._extract_boolean_value(keyword.value)

                # åˆ†æå‡½æ•°è°ƒç”¨ - Column æˆ– relationship            elif keyword.arg == 'primary_key':

                elif isinstance(assign_node.value, ast.Call):                field_info['primary_key'] = self._extract_boolean_value(keyword.value)

                    func_name = self._extract_function_name(assign_node.value.func)            elif keyword.arg == 'unique':

                                    field_info['unique'] = self._extract_boolean_value(keyword.value)

                    if func_name == 'Column':            elif keyword.arg == 'default':

                        field_info = self._analyze_column_from_ast(attr_name, assign_node.value)                field_info['default'] = self._extract_default_value(keyword.value)

                        model_info['fields'].append(field_info)                

                        model_info['raw_fields'][attr_name] = assign_node.value        return field_info

                                

                    elif func_name == 'relationship':    def _extract_column_type(self, type_node) -> str:

                        rel_info = self._analyze_relationship_from_ast(attr_name, assign_node.value)        """æå–åˆ—ç±»å‹"""

                        model_info['relationships'].append(rel_info)        if isinstance(type_node, ast.Name):

                        model_info['raw_relationships'][attr_name] = assign_node.value            return type_node.id

                                elif isinstance(type_node, ast.Call):

    def _extract_function_name(self, func_node) -> str:            return self._get_function_name(type_node.func)

        """æå–å‡½æ•°è°ƒç”¨åç§°"""        return 'Unknown'

        if isinstance(func_node, ast.Name):        

            return func_node.id    def _extract_boolean_value(self, value_node) -> bool:

        elif isinstance(func_node, ast.Attribute):        """æå–å¸ƒå°”å€¼"""

            return func_node.attr        if isinstance(value_node, ast.Constant):

        return 'Unknown'            return bool(value_node.value)

                elif isinstance(value_node, ast.NameConstant):  # Python < 3.8

    def _analyze_column_from_ast(self, field_name: str, call_node: ast.Call) -> Dict:            return bool(value_node.value)

        """ä»ASTåˆ†æColumnå®šä¹‰"""        return False

        field_info = {        

            'name': field_name,    def _extract_default_value(self, value_node) -> Any:

            'column_type': 'Unknown',        """æå–é»˜è®¤å€¼"""

            'nullable': True,  # SQLAlchemyé»˜è®¤å€¼        if isinstance(value_node, ast.Constant):

            'primary_key': False,            return value_node.value

            'foreign_key': None,        elif isinstance(value_node, ast.NameConstant):  # Python < 3.8  

            'unique': False,            return value_node.value

            'default': None,        return None

            'index': False,        

            'constraints': [],    def _analyze_relationship_definition(self, rel_name: str, call_node: ast.Call) -> Dict:

            'max_length': None        """åˆ†ærelationshipå®šä¹‰"""

        }        rel_info = {

                    'name': rel_name,

        # åˆ†æä½ç½®å‚æ•° - ç¬¬ä¸€ä¸ªé€šå¸¸æ˜¯ç±»å‹            'related_model': None,

        if call_node.args:            'back_populates': None,

            type_arg = call_node.args[0]            'cascade': None

            field_info['column_type'] = self._extract_column_type_from_ast(type_arg)        }

                    

        # åˆ†æå…³é”®å­—å‚æ•°        # åˆ†æä½ç½®å‚æ•° - é€šå¸¸ç¬¬ä¸€ä¸ªæ˜¯ç›¸å…³æ¨¡å‹

        for keyword in call_node.keywords:        if call_node.args:

            arg_name = keyword.arg            model_arg = call_node.args[0]

            if arg_name == 'nullable':            if isinstance(model_arg, ast.Constant):

                field_info['nullable'] = self._extract_boolean_from_ast(keyword.value)                rel_info['related_model'] = model_arg.value

            elif arg_name == 'primary_key':                

                field_info['primary_key'] = self._extract_boolean_from_ast(keyword.value)        # åˆ†æå…³é”®å­—å‚æ•°

            elif arg_name == 'unique':        for keyword in call_node.keywords:

                field_info['unique'] = self._extract_boolean_from_ast(keyword.value)            if keyword.arg == 'back_populates':

            elif arg_name == 'index':                if isinstance(keyword.value, ast.Constant):

                field_info['index'] = self._extract_boolean_from_ast(keyword.value)                    rel_info['back_populates'] = keyword.value.value

            elif arg_name == 'default':            elif keyword.arg == 'cascade':

                field_info['default'] = self._extract_literal_value_from_ast(keyword.value)                if isinstance(keyword.value, ast.Constant):

                                    rel_info['cascade'] = keyword.value.value

        return field_info                    

                return rel_info

    def _extract_column_type_from_ast(self, type_node) -> str:        

        """ä»ASTèŠ‚ç‚¹æå–åˆ—ç±»å‹"""    def _analyze_runtime(self, module_name: str) -> Dict[str, Any]:

        if isinstance(type_node, ast.Name):        """è¿è¡Œæ—¶åˆ†æ - å¯¼å…¥æ¨¡å—è·å–å®Œæ•´ç±»ä¿¡æ¯"""

            return type_node.id        try:

        elif isinstance(type_node, ast.Call):            # åŠ¨æ€å¯¼å…¥æ¨¡å—

            func_name = self._extract_function_name(type_node.func)            module_path = f"app.modules.{module_name}.models"

            # å¤„ç†å¸¦å‚æ•°çš„ç±»å‹ï¼Œå¦‚String(50)            spec = importlib.util.spec_from_file_location(

            if func_name and type_node.args:                module_path, 

                if isinstance(type_node.args[0], ast.Constant):                self.project_root / f"app/modules/{module_name}/models.py"

                    return f"{func_name}({type_node.args[0].value})"            )

            return func_name            module = importlib.util.module_from_spec(spec)

        return 'Unknown'            spec.loader.exec_module(module)

                    

    def _extract_boolean_from_ast(self, value_node) -> bool:            models = {}

        """ä»ASTèŠ‚ç‚¹æå–å¸ƒå°”å€¼"""            

        if isinstance(value_node, ast.Constant):            # è·å–æ¨¡å—ä¸­çš„æ‰€æœ‰ç±»

            return bool(value_node.value)            for name, obj in inspect.getmembers(module, inspect.isclass):

        elif hasattr(ast, 'NameConstant') and isinstance(value_node, ast.NameConstant):                if (hasattr(obj, '__tablename__') and 

            return bool(value_node.value)                    hasattr(obj, '__table__')):

        return False                    models[name] = self._extract_runtime_model_info(obj)

                            

    def _extract_literal_value_from_ast(self, value_node) -> Any:            return models

        """ä»ASTèŠ‚ç‚¹æå–å­—é¢å€¼"""            

        if isinstance(value_node, ast.Constant):        except Exception as e:

            return value_node.value            print(f"âš ï¸ è¿è¡Œæ—¶åˆ†æå¤±è´¥: {e}")

        elif hasattr(ast, 'NameConstant') and isinstance(value_node, ast.NameConstant):            return {}

            return value_node.value            

        elif isinstance(value_node, ast.Str):  # Python < 3.8 compatibility    def _extract_runtime_model_info(self, model_class) -> Dict:

            return value_node.s        """ä»è¿è¡Œæ—¶æ¨¡å‹ç±»æå–ä¿¡æ¯"""

        elif isinstance(value_node, ast.Num):  # Python < 3.8 compatibility        table = model_class.__table__

            return value_node.n        

        return None        model_info = {

                    'name': model_class.__name__,

    def _analyze_relationship_from_ast(self, rel_name: str, call_node: ast.Call) -> Dict:            'tablename': table.name,

        """ä»ASTåˆ†ærelationshipå®šä¹‰"""            'fields': [],

        rel_info = {            'relationships': [],

            'name': rel_name,            'primary_keys': [col.name for col in table.primary_key.columns],

            'related_model': None,            'unique_constraints': []

            'back_populates': None,        }

            'cascade': None,        

            'secondary': None,        # åˆ†æå­—æ®µ

            'lazy': None        for column in table.columns:

        }            field_info = FieldInfo(

                        name=column.name,

        # åˆ†æä½ç½®å‚æ•° - ç¬¬ä¸€ä¸ªæ˜¯ç›¸å…³æ¨¡å‹                column_type=str(column.type),

        if call_node.args:                python_type=column.type.python_type.__name__ if hasattr(column.type, 'python_type') else 'str',

            model_arg = call_node.args[0]                nullable=column.nullable,

            if isinstance(model_arg, ast.Constant):                primary_key=column.primary_key,

                rel_info['related_model'] = model_arg.value                foreign_key=str(list(column.foreign_keys)[0].target_fullname) if column.foreign_keys else None,

                                unique=column.unique,

        # åˆ†æå…³é”®å­—å‚æ•°                default=column.default.arg if column.default else None,

        for keyword in call_node.keywords:                constraints=[]

            arg_name = keyword.arg            )

            if arg_name == 'back_populates':            model_info['fields'].append(field_info)

                rel_info['back_populates'] = self._extract_literal_value_from_ast(keyword.value)            

            elif arg_name == 'cascade':        # åˆ†æå…³ç³»

                rel_info['cascade'] = self._extract_literal_value_from_ast(keyword.value)        if hasattr(model_class, '__mapper__'):

            elif arg_name == 'secondary':            for rel_name, relationship in model_class.__mapper__.relationships.items():

                rel_info['secondary'] = self._extract_literal_value_from_ast(keyword.value)                rel_info = RelationshipInfo(

            elif arg_name == 'lazy':                    name=rel_name,

                rel_info['lazy'] = self._extract_literal_value_from_ast(keyword.value)                    related_model=relationship.mapper.class_.__name__,

                                    relationship_type=self._determine_relationship_type(relationship),

        return rel_info                    back_populates=relationship.back_populates,

                            cascade=str(relationship.cascade) if relationship.cascade else None,

    def _analyze_runtime(self, module_name: str) -> Dict[str, Dict]:                    foreign_keys=[str(fk.parent.name) for fk in relationship.foreign_keys]

        """è¿è¡Œæ—¶åˆ†æ - å¯¼å…¥æ¨¡å—è·å–å®Œæ•´ç±»å‹ä¿¡æ¯"""                )

        try:                model_info['relationships'].append(rel_info)

            # åŠ¨æ€å¯¼å…¥æ¨¡å—                

            module_path = f"app.modules.{module_name}.models"        return model_info

            models_file = self.project_root / f"app/modules/{module_name}/models.py"        

                def _determine_relationship_type(self, relationship) -> str:

            spec = importlib.util.spec_from_file_location(module_path, models_file)        """ç¡®å®šå…³ç³»ç±»å‹"""

            if spec is None:        if relationship.uselist:

                raise ImportError(f"æ— æ³•åŠ è½½æ¨¡å—è§„èŒƒ: {module_path}")            return "one-to-many" if not relationship.secondary else "many-to-many"

                        else:

            module = importlib.util.module_from_spec(spec)            return "one-to-one"

                        

            # æ‰§è¡Œæ¨¡å—ä»¥è·å–å®Œæ•´ä¿¡æ¯    def _merge_analysis_results(self, ast_models: Dict, runtime_models: Dict) -> Dict[str, ModelInfo]:

            spec.loader.exec_module(module)        """åˆå¹¶ASTå’Œè¿è¡Œæ—¶åˆ†æç»“æœ"""

                    merged = {}

            models = {}        

                    # ä»¥è¿è¡Œæ—¶åˆ†æä¸ºå‡†ï¼ŒASTåˆ†æè¡¥å……

            # è·å–æ‰€æœ‰SQLAlchemyæ¨¡å‹ç±»        for model_name, runtime_info in runtime_models.items():

            for name, obj in inspect.getmembers(module, inspect.isclass):            ast_info = ast_models.get(model_name, {})

                if (hasattr(obj, '__tablename__') and             

                    hasattr(obj, '__table__')):            merged[model_name] = ModelInfo(

                    models[name] = self._extract_runtime_model_info(obj)                name=model_name,

                                    tablename=runtime_info['tablename'],

            return models                fields=runtime_info['fields'],

                            relationships=runtime_info['relationships'],

        except Exception as e:                mixins=ast_info.get('mixins', []),

            print(f"âš ï¸ è¿è¡Œæ—¶åˆ†æå¤±è´¥: {e}")                docstring=ast_info.get('docstring'),

            return {}                primary_keys=runtime_info.get('primary_keys', []),

                            unique_constraints=runtime_info.get('unique_constraints', [])

    def _extract_runtime_model_info(self, model_class) -> Dict:            )

        """ä»è¿è¡Œæ—¶æ¨¡å‹ç±»æå–å®Œæ•´ä¿¡æ¯"""            

        table = model_class.__table__        return merged

                    return {}

        model_info = {            

            'name': model_class.__name__,        # 2. è¿è¡Œæ—¶åˆ†æï¼ˆå¯¼å…¥æ¨¡å—è·å–å®Œæ•´ä¿¡æ¯ï¼‰

            'tablename': table.name,        models = self._analyze_runtime_models(module_name)

            'fields': [],        print(f"âœ… å‘ç° {len(models)} ä¸ªæ•°æ®æ¨¡å‹")

            'relationships': [],        

            'primary_keys': [col.name for col in table.primary_key.columns],        # ç¼“å­˜ç»“æœ

            'unique_constraints': [],        self.models_cache[module_name] = models

            'indexes': [idx.name for idx in table.indexes] if hasattr(table, 'indexes') else []        return models

        }        

            def _analyze_runtime_models(self, module_name: str) -> Dict[str, ModelInfo]:

        # åˆ†æè¡¨å­—æ®µ        """è¿è¡Œæ—¶åˆ†æ - å¯¼å…¥æ¨¡å—è·å–å®Œæ•´ç±»ä¿¡æ¯"""

        for column in table.columns:        try:

            field_info = FieldInfo(            # åŠ¨æ€å¯¼å…¥æ¨¡å—

                name=column.name,            module_path = f"app.modules.{module_name}.models"

                column_type=str(column.type),            spec = importlib.util.spec_from_file_location(

                python_type=self._get_python_type_from_column(column),                module_path, 

                nullable=column.nullable,                self.project_root / f"app/modules/{module_name}/models.py"

                primary_key=column.primary_key,            )

                foreign_key=self._extract_foreign_key_info(column),            module = importlib.util.module_from_spec(spec)

                unique=column.unique or False,            spec.loader.exec_module(module)

                default=self._extract_column_default(column),            

                index=column.index or False,            models = {}

                max_length=self._extract_column_max_length(column),            

                server_default=self._extract_server_default(column)            # è·å–æ¨¡å—ä¸­çš„æ‰€æœ‰SQLAlchemyæ¨¡å‹ç±»

            )            for name, obj in inspect.getmembers(module, inspect.isclass):

            model_info['fields'].append(field_info)                if (hasattr(obj, '__tablename__') and 

                                hasattr(obj, '__table__') and

        # åˆ†æè¡¨å…³ç³»                    obj.__module__ == module_path):  # ç¡®ä¿æ˜¯å½“å‰æ¨¡å—å®šä¹‰çš„ç±»

        if hasattr(model_class, '__mapper__'):                    model_info = self._extract_model_info(obj)

            for rel_name, relationship in model_class.__mapper__.relationships.items():                    models[name] = model_info

                rel_info = RelationshipInfo(                    print(f"  ğŸ“‹ {name}: {len(model_info.fields)}å­—æ®µ, {len(model_info.relationships)}å…³ç³»")

                    name=rel_name,                    

                    related_model=relationship.mapper.class_.__name__,            return models

                    relationship_type=self._determine_relationship_type(relationship),            

                    back_populates=relationship.back_populates,        except Exception as e:

                    cascade=str(relationship.cascade) if relationship.cascade else None,            print(f"âŒ æ¨¡å‹åˆ†æå¤±è´¥: {e}")

                    foreign_keys=[fk.parent.name for fk in relationship.foreign_keys],            return {}

                    secondary=relationship.secondary.name if relationship.secondary is not None else None,            

                    lazy=str(relationship.lazy) if relationship.lazy else None    def _extract_model_info(self, model_class) -> ModelInfo:

                )        """ä»SQLAlchemyæ¨¡å‹ç±»æå–å®Œæ•´ä¿¡æ¯"""

                model_info['relationships'].append(rel_info)        table = model_class.__table__

                

        # åˆ†æå”¯ä¸€çº¦æŸ        # åŸºç¡€ä¿¡æ¯

        for constraint in table.constraints:        model_info = ModelInfo(

            if hasattr(constraint, 'columns') and len(constraint.columns) > 1:            name=model_class.__name__,

                if constraint.__class__.__name__ == 'UniqueConstraint':            tablename=table.name,

                    model_info['unique_constraints'].append([col.name for col in constraint.columns])            fields=[],

                                relationships=[],

        return model_info            mixins=self._extract_mixins(model_class),

                    docstring=inspect.getdoc(model_class),

    def _get_python_type_from_column(self, column) -> str:            primary_keys=[col.name for col in table.primary_key.columns],

        """è·å–åˆ—å¯¹åº”çš„Pythonç±»å‹"""            unique_constraints=[]

        try:        )

            if hasattr(column.type, 'python_type'):        

                return column.type.python_type.__name__        # åˆ†æå­—æ®µ

            else:        for column in table.columns:

                # æ ¹æ®SQLAlchemyç±»å‹æ¨æ–­Pythonç±»å‹            field_info = FieldInfo(

                type_str = str(column.type).lower()                name=column.name,

                if 'int' in type_str:                column_type=str(column.type),

                    return 'int'                python_type=self._get_python_type(column.type),

                elif 'float' in type_str or 'decimal' in type_str or 'numeric' in type_str:                nullable=column.nullable,

                    return 'float'                primary_key=column.primary_key,

                elif 'bool' in type_str:                foreign_key=str(list(column.foreign_keys)[0].target_fullname) if column.foreign_keys else None,

                    return 'bool'                unique=column.unique,

                elif 'date' in type_str:                default=column.default.arg if column.default else None,

                    return 'datetime'                constraints=self._extract_constraints(column)

                else:            )

                    return 'str'            model_info.fields.append(field_info)

        except:            

            return 'str'        # åˆ†æå…³ç³»

                    if hasattr(model_class, '__mapper__'):

    def _extract_foreign_key_info(self, column) -> Optional[str]:            for rel_name, relationship in model_class.__mapper__.relationships.items():

        """æå–å¤–é”®ä¿¡æ¯"""                rel_info = RelationshipInfo(

        if column.foreign_keys:                    name=rel_name,

            fk = list(column.foreign_keys)[0]                    related_model=relationship.mapper.class_.__name__,

            return str(fk.target_fullname)                    relationship_type=self._determine_relationship_type(relationship),

        return None                    back_populates=relationship.back_populates,

                            cascade=str(relationship.cascade) if relationship.cascade else None,

    def _extract_column_default(self, column) -> Any:                    foreign_keys=[str(fk.parent.name) for fk in relationship.foreign_keys]

        """æå–åˆ—é»˜è®¤å€¼"""                )

        if column.default is not None:                model_info.relationships.append(rel_info)

            if hasattr(column.default, 'arg'):                

                return column.default.arg        return model_info

            elif hasattr(column.default, 'is_scalar') and column.default.is_scalar:        

                return column.default.arg    def _extract_mixins(self, model_class) -> List[str]:

        return None        """æå–æ¨¡å‹ç»§æ‰¿çš„æ··å…¥ç±»"""

                mixins = []

    def _extract_server_default(self, column) -> Any:        for base in model_class.__mro__:

        """æå–æœåŠ¡å™¨ç«¯é»˜è®¤å€¼"""            if (base.__name__ not in ['object', 'Base', model_class.__name__] and 

        if column.server_default is not None:                'Mixin' in base.__name__):

            if hasattr(column.server_default, 'arg'):                mixins.append(base.__name__)

                return str(column.server_default.arg)        return mixins

        return None        

            def _get_python_type(self, column_type) -> str:

    def _extract_column_max_length(self, column) -> Optional[int]:        """è·å–åˆ—ç±»å‹å¯¹åº”çš„Pythonç±»å‹"""

        """æå–åˆ—æœ€å¤§é•¿åº¦"""        try:

        try:            return column_type.python_type.__name__

            if hasattr(column.type, 'length') and column.type.length:        except:

                return column.type.length            return 'str'  # é»˜è®¤å­—ç¬¦ä¸²ç±»å‹

        except:            

            pass    def _extract_constraints(self, column) -> List[str]:

        return None        """æå–åˆ—çº¦æŸä¿¡æ¯"""

                constraints = []

    def _determine_relationship_type(self, relationship) -> str:        if column.primary_key:

        """ç¡®å®šå…³ç³»ç±»å‹"""            constraints.append('PRIMARY KEY')

        if relationship.secondary is not None:        if not column.nullable:

            return "many-to-many"            constraints.append('NOT NULL')

        elif relationship.uselist:        if column.unique:

            return "one-to-many"            constraints.append('UNIQUE')

        else:        if column.foreign_keys:

            return "one-to-one"            constraints.append('FOREIGN KEY')

                    return constraints

    def _merge_analysis_results(self, ast_models: Dict, runtime_models: Dict) -> Dict[str, ModelInfo]:        

        """åˆå¹¶ASTå’Œè¿è¡Œæ—¶åˆ†æç»“æœ"""    def _determine_relationship_type(self, relationship) -> str:

        merged = {}        """ç¡®å®šå…³ç³»ç±»å‹"""

                if relationship.uselist:

        # ä»¥è¿è¡Œæ—¶åˆ†æä¸ºå‡†ï¼ŒASTåˆ†ææä¾›è¡¥å……ä¿¡æ¯            return "one-to-many" if not hasattr(relationship, 'secondary') or relationship.secondary is None else "many-to-many"

        for model_name, runtime_info in runtime_models.items():        else:

            ast_info = ast_models.get(model_name, {})            return "one-to-one"

                

            # åˆ›å»ºå®Œæ•´çš„ModelInfoå¯¹è±¡    def generate_unit_tests(self, module_name: str) -> Dict[str, str]:

            merged[model_name] = ModelInfo(        """ç”Ÿæˆå•å…ƒæµ‹è¯• (70% - Mock + SQLiteå†…å­˜)"""

                name=model_name,        

                tablename=runtime_info['tablename'],        # Mockæ¨¡å‹æµ‹è¯• (test_models/)

                fields=runtime_info['fields'],        mock_tests = self._generate_mock_model_tests(module_name)

                relationships=runtime_info['relationships'],        

                mixins=ast_info.get('mixins', []),        # æœåŠ¡å±‚æµ‹è¯• (test_services/) 

                docstring=ast_info.get('docstring'),        service_tests = self._generate_service_tests(module_name)

                primary_keys=runtime_info.get('primary_keys', []),        

                unique_constraints=runtime_info.get('unique_constraints', []),        # ç‹¬ç«‹ä¸šåŠ¡æµç¨‹æµ‹è¯• (*_standalone.py)

                indexes=runtime_info.get('indexes', [])        standalone_tests = self._generate_standalone_tests(module_name)

            )        

                    return {

        return merged            f'tests/unit/test_models/test_{module_name}_models.py': mock_tests,

                    f'tests/unit/test_services/test_{module_name}_service.py': service_tests, 

    def _validate_analysis_results(self, models: Dict[str, ModelInfo]):            f'tests/unit/test_{module_name}_standalone.py': standalone_tests

        """éªŒè¯åˆ†æç»“æœçš„å®Œæ•´æ€§å’Œå‡†ç¡®æ€§"""        }

        for model_name, model in models.items():    

            # éªŒè¯åŸºæœ¬ä¿¡æ¯    def _generate_mock_model_tests(self, module_name: str) -> str:

            if not model.tablename:        """ç”ŸæˆMockæ¨¡å‹æµ‹è¯• - åŸºäºæ™ºèƒ½åˆ†æï¼Œä¸ºæ¯ä¸ªæ¨¡å‹ç”Ÿæˆæµ‹è¯•ç±»"""

                print(f"âš ï¸ æ¨¡å‹ {model_name} ç¼ºå°‘è¡¨å")        

                        # åˆ†ææ¨¡å—ä¸­çš„æ‰€æœ‰æ¨¡å‹

            if not model.fields:        models = self.analyze_module_models(module_name)

                print(f"âš ï¸ æ¨¡å‹ {model_name} æ²¡æœ‰å­—æ®µå®šä¹‰")        

                        if not models:

            # éªŒè¯ä¸»é”®            return self._generate_fallback_mock_tests(module_name)

            pk_fields = [f for f in model.fields if f.primary_key]            

            if not pk_fields and not model.primary_keys:        # ç”Ÿæˆæ–‡ä»¶å¤´éƒ¨

                print(f"âš ï¸ æ¨¡å‹ {model_name} æ²¡æœ‰ä¸»é”®å®šä¹‰")        imports = [

                            f"from app.modules.{module_name}.models import {', '.join(models.keys())}",

            # éªŒè¯å¤–é”®å¼•ç”¨        ]

            for field in model.foreign_key_fields:        

                if field.foreign_key:        test_classes = []

                    referenced_table = field.foreign_key.split('.')[0]        

                    print(f"ğŸ”— {model_name}.{field.name} -> {field.foreign_key}")        # ä¸ºæ¯ä¸ªæ¨¡å‹ç”Ÿæˆæµ‹è¯•ç±»

                            for model_name, model_info in models.items():

    def generate_analysis_report(self, models: Dict[str, ModelInfo]) -> str:            test_class = self._generate_model_test_class(model_name, model_info, module_name)

        """ç”Ÿæˆè¯¦ç»†çš„æ¨¡å‹åˆ†ææŠ¥å‘Š"""            test_classes.append(test_class)

        report_lines = []            

        report_lines.append("# æ™ºèƒ½æ¨¡å‹åˆ†ææŠ¥å‘Š")        return f'''"""

        report_lines.append(f"**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}"){module_name.title()} æ¨¡å‹æ™ºèƒ½æµ‹è¯•å¥—ä»¶

        report_lines.append(f"**åˆ†ææ¨¡å‹æ•°é‡**: {len(models)}")

        report_lines.append("")æµ‹è¯•ç±»å‹: å•å…ƒæµ‹è¯• (Mock + æ™ºèƒ½åˆ†æ)

        æ•°æ®ç­–ç•¥: 100% Mockå¯¹è±¡ï¼Œæ— æ•°æ®åº“ä¾èµ–

        # ç»Ÿè®¡ä¿¡æ¯ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

        total_fields = sum(len(model.fields) for model in models.values())æ¨¡å‹æ•°é‡: {len(models)}

        total_relationships = sum(len(model.relationships) for model in models.values())

        total_foreign_keys = sum(len(model.foreign_key_fields) for model in models.values())æ ¹æ®testing-standards.mdç¬¬32-45è¡ŒMockæµ‹è¯•è§„èŒƒ

        åŸºäºæ™ºèƒ½æ¨¡å‹åˆ†æè‡ªåŠ¨ç”Ÿæˆ

        report_lines.append("## ğŸ“Š ç»Ÿè®¡æ¦‚è§ˆ")"""

        report_lines.append(f"- **æ€»å­—æ®µæ•°**: {total_fields}")

        report_lines.append(f"- **æ€»å…³ç³»æ•°**: {total_relationships}")import pytest

        report_lines.append(f"- **å¤–é”®å­—æ®µ**: {total_foreign_keys}")from unittest.mock import Mock, patch, MagicMock

        report_lines.append("")from datetime import datetime, date

        from decimal import Decimal

        # è¯¦ç»†æ¨¡å‹ä¿¡æ¯

        for model_name, model in models.items():# æµ‹è¯•å·¥å‚å¯¼å…¥ - Factory Boyæ¨¡å¼  

            report_lines.append(f"## ğŸ—ï¸ {model_name} æ¨¡å‹")from tests.factories import StandardTestDataFactory, TestDataValidator

            report_lines.append(f"- **è¡¨å**: `{model.tablename}`")

            report_lines.append(f"- **å­—æ®µæ•°**: {len(model.fields)}")# æ¨¡å‹å¯¼å…¥

            report_lines.append(f"- **å…³ç³»æ•°**: {len(model.relationships)}"){chr(10).join(imports)}

            report_lines.append(f"- **æ··å…¥**: {', '.join(model.mixins) if model.mixins else 'æ— '}")

            

            if model.docstring:{chr(10).join(test_classes)}

                report_lines.append(f"- **è¯´æ˜**: {model.docstring.split('.')[0]}...")'''

            

            # å­—æ®µè¯¦æƒ…    def _generate_model_test_class(self, model_name: str, model_info: ModelInfo, module_name: str) -> str:

            report_lines.append("### ğŸ“ å­—æ®µè¯¦æƒ…")        """ä¸ºå•ä¸ªæ¨¡å‹ç”Ÿæˆæµ‹è¯•ç±»"""

            for field in model.fields:        

                constraints = []        # ç”Ÿæˆå­—æ®µæµ‹è¯•

                if field.primary_key:        field_tests = []

                    constraints.append("ä¸»é”®")        for field in model_info.fields:

                if not field.nullable:            field_test = self._generate_field_test(field, model_name)

                    constraints.append("å¿…å¡«")            if field_test:

                if field.unique:                field_tests.append(field_test)

                    constraints.append("å”¯ä¸€")                

                if field.foreign_key:        # ç”Ÿæˆå…³ç³»æµ‹è¯•

                    constraints.append(f"å¤–é”®â†’{field.foreign_key}")        relationship_tests = []

                if field.index:        for rel in model_info.relationships:

                    constraints.append("ç´¢å¼•")            rel_test = self._generate_relationship_test(rel, model_name)

                                if rel_test:

                constraint_text = f" [{', '.join(constraints)}]" if constraints else ""                relationship_tests.append(rel_test)

                default_text = f" (é»˜è®¤: {field.default})" if field.default is not None else ""        

                        return f'''

                report_lines.append(f"- **{field.name}**: {field.column_type}{constraint_text}{default_text}")class Test{model_name}Model:

                    """æ™ºèƒ½ç”Ÿæˆçš„{model_name}æ¨¡å‹æµ‹è¯•"""

            # å…³ç³»è¯¦æƒ…    

            if model.relationships:    def setup_method(self):

                report_lines.append("### ğŸ”— å…³ç³»è¯¦æƒ…")        """æµ‹è¯•å‡†å¤‡"""

                for rel in model.relationships:        self.mock_{model_name.lower()} = Mock()

                    cascade_text = f" (çº§è”: {rel.cascade})" if rel.cascade else ""        self.test_data = StandardTestDataFactory.create_{model_name.lower()}_data()

                    report_lines.append(f"- **{rel.name}**: {rel.relationship_type} â†’ {rel.related_model}{cascade_text}")        

                        def test_{model_name.lower()}_model_structure(self):

            report_lines.append("")        """æµ‹è¯•{model_name}æ¨¡å‹ç»“æ„"""

                    # éªŒè¯è¡¨å

        return "\n".join(report_lines)        assert {model_name}.__tablename__ == '{model_info.tablename}'

        

        # éªŒè¯ä¸»é”®å­—æ®µ

def main():        primary_keys = {model_info.primary_keys}

    """ä¸»å‡½æ•° - è§£æå‚æ•°å¹¶æ‰§è¡Œæµ‹è¯•ç”Ÿæˆ"""        assert len(primary_keys) > 0, "æ¨¡å‹å¿…é¡»æœ‰ä¸»é”®"

    parser = argparse.ArgumentParser(        

        description='äº”å±‚æ¶æ„æ™ºèƒ½æµ‹è¯•ç”Ÿæˆå™¨ v2.0',    def test_{model_name.lower()}_model_fields(self):

        formatter_class=argparse.RawDescriptionHelpFormatter,        """æµ‹è¯•{model_name}æ¨¡å‹å­—æ®µå®šä¹‰"""

        epilog="""        # éªŒè¯æ‰€æœ‰å­—æ®µå­˜åœ¨

ç¤ºä¾‹:        expected_fields = {[f"'{field.name}'" for field in model_info.fields]}

  python scripts/generate_test_template.py user_auth --type all --validate        for field_name in expected_fields:

  python scripts/generate_test_template.py shopping_cart --type unit --dry-run            assert hasattr({model_name}, field_name), f"å­—æ®µ {{field_name}} ä¸å­˜åœ¨"

  python scripts/generate_test_template.py payment_service --detailed            

        """{chr(10).join(field_tests)}

    )

    {chr(10).join(relationship_tests)}

    parser.add_argument('module_name', 

                       help='è¦åˆ†æå’Œç”Ÿæˆæµ‹è¯•çš„æ¨¡å—åç§°')    def test_{model_name.lower()}_repr(self, mocker):

    parser.add_argument('--type',         """æµ‹è¯•{model_name}æ¨¡å‹å­—ç¬¦ä¸²è¡¨ç¤º"""

                       choices=['all', 'unit', 'integration', 'smoke', 'e2e', 'specialized'],        mock_instance = mocker.Mock(spec={model_name})

                       default='all',        mock_instance.id = 1

                       help='è¦ç”Ÿæˆçš„æµ‹è¯•ç±»å‹ (é»˜è®¤: all)')        {self._generate_repr_setup(model_info)}

    parser.add_argument('--validate',         

                       action='store_true',        # æ¨¡æ‹Ÿ__repr__æ–¹æ³•

                       help='ç”Ÿæˆåè‡ªåŠ¨éªŒè¯æµ‹è¯•æ–‡ä»¶')        result = f"<{model_name}(id={{mock_instance.id}})>"

    parser.add_argument('--dry-run',        assert result is not None

                       action='store_true', '''

                       help='ä»…åˆ†ææ¨¡å‹ï¼Œä¸ç”Ÿæˆæ–‡ä»¶')

    parser.add_argument('--detailed',    def _generate_field_test(self, field: FieldInfo, model_name: str) -> str:

                       action='store_true',        """ç”Ÿæˆå­—æ®µæµ‹è¯•æ–¹æ³•"""

                       help='è¾“å‡ºè¯¦ç»†åˆ†ææŠ¥å‘Š')        

    parser.add_argument('--force',        test_cases = []

                       action='store_true',        

                       help='å¼ºåˆ¶è¦†ç›–existing files')        # ä¸»é”®æµ‹è¯•

            if field.primary_key:

    args = parser.parse_args()            test_cases.append(f"        # {field.name}æ˜¯ä¸»é”®")

                test_cases.append(f"        assert {model_name}.__table__.columns['{field.name}'].primary_key")

    try:            

        # åˆ›å»ºæ™ºèƒ½åˆ†æå™¨        # éç©ºçº¦æŸæµ‹è¯•

        analyzer = IntelligentModelAnalyzer(project_root)        if not field.nullable:

                    test_cases.append(f"        # {field.name}ä¸èƒ½ä¸ºç©º")

        # åˆ†ææ¨¡å—            test_cases.append(f"        assert not {model_name}.__table__.columns['{field.name}'].nullable")

        models = analyzer.analyze_module(args.module_name)            

                # å”¯ä¸€çº¦æŸæµ‹è¯•  

        if not models:        if field.unique:

            print(f"âŒ æ¨¡å— {args.module_name} ä¸­æ²¡æœ‰å‘ç°ä»»ä½•æ¨¡å‹")            test_cases.append(f"        # {field.name}å¿…é¡»å”¯ä¸€")

            return 1            test_cases.append(f"        assert {model_name}.__table__.columns['{field.name}'].unique")

                        

        # è¾“å‡ºè¯¦ç»†æŠ¥å‘Š        # å¤–é”®æµ‹è¯•

        if args.detailed or args.dry_run:        if field.foreign_key:

            report = analyzer.generate_analysis_report(models)            test_cases.append(f"        # {field.name}æ˜¯å¤–é”®")

            print("\n" + report)            test_cases.append(f"        assert len({model_name}.__table__.columns['{field.name}'].foreign_keys) > 0")

                        

        if args.dry_run:        if not test_cases:

            print("ğŸ” å¹²è¿è¡Œæ¨¡å¼å®Œæˆ")            return ""

            return 0            

                    return f'''

        # TODO: åœ¨åç»­ä»»åŠ¡ä¸­å®ç°å®Œæ•´çš„æµ‹è¯•ç”ŸæˆåŠŸèƒ½    def test_{field.name}_field_constraints(self):

        print("ğŸš§ å®Œæ•´æµ‹è¯•ç”ŸæˆåŠŸèƒ½å°†åœ¨ä¸‹ä¸€ä¸ªTODOä»»åŠ¡ä¸­å®ç°")        """æµ‹è¯•{field.name}å­—æ®µçº¦æŸ"""

        print("âœ… ä»»åŠ¡2å®Œæˆï¼šæ™ºèƒ½æ¨¡å‹åˆ†æå™¨å·²æˆåŠŸæ•´åˆ"){chr(10).join(test_cases)}'''

        

        return 0    def _generate_relationship_test(self, rel: RelationshipInfo, model_name: str) -> str:

                """ç”Ÿæˆå…³ç³»æµ‹è¯•æ–¹æ³•"""

    except Exception as e:        return f'''

        print(f"âŒ æ‰§è¡Œå¤±è´¥: {e}")    def test_{rel.name}_relationship(self):

        return 1        """æµ‹è¯•{rel.name}å…³ç³»å®šä¹‰"""

        # éªŒè¯å…³ç³»å­˜åœ¨

        assert hasattr({model_name}, '{rel.name}')

if __name__ == "__main__":        

    sys.exit(main())        # éªŒè¯å…³ç³»ç±»å‹: {rel.relationship_type}
        relationship = {model_name}.__mapper__.relationships['{rel.name}']
        assert relationship is not None'''

    def _generate_repr_setup(self, model_info: ModelInfo) -> str:
        """ç”Ÿæˆrepræµ‹è¯•çš„æ•°æ®è®¾ç½®"""
        setup_lines = []
        for field in model_info.fields[:3]:  # åªå–å‰3ä¸ªå­—æ®µä½œä¸ºç¤ºä¾‹
            if field.name != 'id':
                if field.python_type == 'str':
                    setup_lines.append(f"        mock_instance.{field.name} = 'test_{field.name}'")
                elif field.python_type in ['int', 'Integer']:
                    setup_lines.append(f"        mock_instance.{field.name} = 123")
                elif field.python_type == 'bool':
                    setup_lines.append(f"        mock_instance.{field.name} = True")
        return "\n".join(setup_lines)
        
    def _generate_fallback_mock_tests(self, module_name: str) -> str:
        """å½“æ™ºèƒ½åˆ†æå¤±è´¥æ—¶çš„å¤‡ç”¨ç”Ÿæˆæ–¹æ¡ˆ"""
        return f'''"""
{module_name.title()} æ¨¡å‹Mockæµ‹è¯•å¥—ä»¶ (å¤‡ç”¨æ–¹æ¡ˆ)

æµ‹è¯•ç±»å‹: å•å…ƒæµ‹è¯• (Mock)
æ•°æ®ç­–ç•¥: 100% Mockå¯¹è±¡ï¼Œæ— æ•°æ®åº“ä¾èµ–
ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

æ³¨æ„: æ™ºèƒ½åˆ†æå¤±è´¥ï¼Œä½¿ç”¨å¤‡ç”¨æ¨¡æ¿
"""

import pytest
from unittest.mock import Mock, patch, MagicMock
from datetime import datetime, date

# æµ‹è¯•å·¥å‚å¯¼å…¥ - Factory Boyæ¨¡å¼
from tests.factories import StandardTestDataFactory


class TestMock{module_name.title()}Model:
    """Mock {module_name} æ¨¡å‹æµ‹è¯• (å¤‡ç”¨)"""
    
    def setup_method(self):
        """æ¯ä¸ªæµ‹è¯•æ–¹æ³•å‰çš„å‡†å¤‡"""
        self.mock_{module_name} = Mock()
        
    def test_model_validation_with_valid_data(self, mocker):
        """æµ‹è¯•æ¨¡å‹éªŒè¯ - æœ‰æ•ˆæ•°æ®"""
        # ä½¿ç”¨Factory Boyåˆ›å»ºMockæ•°æ®
        mock_data = StandardTestDataFactory.create_generic_data()
        mock_validator = mocker.Mock()
        mock_validator.validate.return_value = True
        
        # æ‰§è¡ŒéªŒè¯
        result = mock_validator.validate(mock_data)
        
        # éªŒè¯è°ƒç”¨
        assert result is True
        mock_validator.validate.assert_called_once_with(mock_data)
'''
        
        # éªŒè¯è°ƒç”¨
        assert result is True
        mock_validator.validate.assert_called_once_with(mock_data)
        
    def test_model_validation_with_invalid_data(self, mocker):
        """æµ‹è¯•æ¨¡å‹éªŒè¯ - æ— æ•ˆæ•°æ®"""
        mock_validator = mocker.Mock()
        mock_validator.validate.side_effect = ValueError("Validation failed")
        
        # éªŒè¯å¼‚å¸¸æŠ›å‡º
        with pytest.raises(ValueError, match="Validation failed"):
            mock_validator.validate({{"invalid": "data"}})
            
    @pytest.mark.parametrize("field_name,field_value,expected", [
        ("status", "active", True),
        ("status", "inactive", False), 
        ("status", None, False),
    ])
    def test_status_field_validation(self, field_name, field_value, expected, mocker):
        """å‚æ•°åŒ–æµ‹è¯•çŠ¶æ€å­—æ®µéªŒè¯"""
        mock_model = mocker.Mock()
        mock_model.status = field_value
        
        # MockéªŒè¯é€»è¾‘
        result = field_value == "active" if field_value else False
        assert result == expected
'''
    
    def _generate_service_tests(self, module_name: str) -> str:
        """ç”ŸæˆæœåŠ¡å±‚æµ‹è¯• - SQLiteå†…å­˜æ•°æ®åº“"""
        return f'''"""
{module_name.title()} æœåŠ¡å±‚æµ‹è¯•å¥—ä»¶

æµ‹è¯•ç±»å‹: å•å…ƒæµ‹è¯• (Service)
æ•°æ®ç­–ç•¥: SQLiteå†…å­˜æ•°æ®åº“, unit_test_db fixture
ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

æ ¹æ®testing-standards.mdç¬¬54-68è¡ŒæœåŠ¡æµ‹è¯•è§„èŒƒ
"""

import pytest
from sqlalchemy.orm import Session

# æµ‹è¯•å·¥å‚å¯¼å…¥
from tests.factories import {module_name.title()}Factory, UserFactory

# Fixtureå¯¼å…¥
from tests.conftest import unit_test_db

# è¢«æµ‹æ¨¡å—å¯¼å…¥
from app.modules.{module_name}.service import {module_name.title()}Service
from app.modules.{module_name}.models import {module_name.title()}


class Test{module_name.title()}Service:
    """æœåŠ¡å±‚ä¸šåŠ¡é€»è¾‘æµ‹è¯•"""
    
    def setup_method(self):
        """æµ‹è¯•å‡†å¤‡"""
        self.test_data = {module_name.title()}Factory.build_dict()
        
    def test_create_{module_name}_with_valid_data(self, unit_test_db: Session):
        """æµ‹è¯•åˆ›å»º{module_name} - æœ‰æ•ˆæ•°æ®"""
        # Arrange
        service = {module_name.title()}Service(unit_test_db)
        create_data = self.test_data
        
        # Act
        created_{module_name} = service.create(create_data)
        
        # Assert
        assert created_{module_name} is not None
        assert created_{module_name}.id is not None
        assert hasattr(created_{module_name}, 'created_at')
        
        # éªŒè¯æ•°æ®åº“å­˜å‚¨
        db_{module_name} = unit_test_db.query({module_name.title()}).filter_by(
            id=created_{module_name}.id
        ).first()
        assert db_{module_name} is not None
        
    def test_get_{module_name}_by_id_exists(self, unit_test_db: Session):
        """æµ‹è¯•æŒ‰IDæŸ¥è¯¢{module_name} - å­˜åœ¨"""
        # å‡†å¤‡æµ‹è¯•æ•°æ®
        {module_name}_data = {module_name.title()}Factory.create_dict()
        service = {module_name.title()}Service(unit_test_db)
        created = service.create({module_name}_data)
        
        # æ‰§è¡ŒæŸ¥è¯¢
        found_{module_name} = service.get_by_id(created.id)
        
        # éªŒè¯ç»“æœ
        assert found_{module_name} is not None
        assert found_{module_name}.id == created.id
        
    def test_get_{module_name}_by_id_not_exists(self, unit_test_db: Session):
        """æµ‹è¯•æŒ‰IDæŸ¥è¯¢{module_name} - ä¸å­˜åœ¨"""
        service = {module_name.title()}Service(unit_test_db)
        
        # æŸ¥è¯¢ä¸å­˜åœ¨çš„ID
        result = service.get_by_id(99999)
        
        # éªŒè¯è¿”å›None
        assert result is None
        
    def test_update_{module_name}_success(self, unit_test_db: Session):
        """æµ‹è¯•æ›´æ–°{module_name} - æˆåŠŸ"""
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        service = {module_name.title()}Service(unit_test_db)
        created = service.create(self.test_data)
        
        # å‡†å¤‡æ›´æ–°æ•°æ®
        update_data = {{"status": "updated"}}
        
        # æ‰§è¡Œæ›´æ–°
        updated = service.update(created.id, update_data)
        
        # éªŒè¯æ›´æ–°ç»“æœ
        assert updated is not None
        assert updated.status == "updated"
        assert hasattr(updated, 'updated_at')
        
    def test_delete_{module_name}_success(self, unit_test_db: Session):
        """æµ‹è¯•åˆ é™¤{module_name} - æˆåŠŸ"""
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        service = {module_name.title()}Service(unit_test_db)
        created = service.create(self.test_data)
        
        # æ‰§è¡Œåˆ é™¤
        result = service.delete(created.id)
        
        # éªŒè¯åˆ é™¤ç»“æœ
        assert result is True
        
        # éªŒè¯æ•°æ®åº“ä¸­å·²åˆ é™¤
        deleted = service.get_by_id(created.id)
        assert deleted is None
'''

    def _generate_standalone_tests(self, module_name: str) -> str:
        """ç”Ÿæˆç‹¬ç«‹ä¸šåŠ¡æµç¨‹æµ‹è¯• - SQLiteå†…å­˜æ•°æ®åº“"""
        return f'''"""
{module_name.title()} ç‹¬ç«‹ä¸šåŠ¡æµç¨‹æµ‹è¯•å¥—ä»¶

æµ‹è¯•ç±»å‹: å•å…ƒæµ‹è¯• (Standalone Business Flow)
æ•°æ®ç­–ç•¥: SQLiteå†…å­˜æ•°æ®åº“, unit_test_db fixture
ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

æ ¹æ®testing-standards.mdç¬¬78-92è¡Œä¸šåŠ¡æµç¨‹æµ‹è¯•è§„èŒƒ
"""

import pytest
from sqlalchemy.orm import Session

# æµ‹è¯•å·¥å‚å¯¼å…¥
from tests.factories import {module_name.title()}Factory, UserFactory

# Fixtureå¯¼å…¥  
from tests.conftest import unit_test_db

# è¢«æµ‹æ¨¡å—å¯¼å…¥
from app.modules.{module_name}.service import {module_name.title()}Service
from app.modules.{module_name}.models import {module_name.title()}


class Test{module_name.title()}BusinessFlow:
    """ç‹¬ç«‹ä¸šåŠ¡æµç¨‹æµ‹è¯•"""
    
    def setup_method(self):
        """æµ‹è¯•å‡†å¤‡"""
        self.user_data = UserFactory.build_dict()
        self.{module_name}_data = {module_name.title()}Factory.build_dict()
        
    def test_complete_{module_name}_workflow(self, unit_test_db: Session):
        """æµ‹è¯•å®Œæ•´{module_name}ä¸šåŠ¡æµç¨‹"""
        service = {module_name.title()}Service(unit_test_db)
        
        # æ­¥éª¤1: åˆ›å»º{module_name}
        created = service.create(self.{module_name}_data)
        assert created is not None
        assert created.id is not None
        
        # æ­¥éª¤2: æŸ¥è¯¢éªŒè¯
        found = service.get_by_id(created.id)
        assert found is not None
        assert found.id == created.id
        
        # æ­¥éª¤3: æ›´æ–°çŠ¶æ€
        update_result = service.update(created.id, {{"status": "processed"}})
        assert update_result.status == "processed"
        
        # æ­¥éª¤4: æœ€ç»ˆéªŒè¯
        final_check = service.get_by_id(created.id)
        assert final_check.status == "processed"
        
    def test_{module_name}_error_handling_flow(self, unit_test_db: Session):
        """æµ‹è¯•{module_name}é”™è¯¯å¤„ç†æµç¨‹"""
        service = {module_name.title()}Service(unit_test_db)
        
        # æµ‹è¯•æ— æ•ˆæ•°æ®å¤„ç†
        with pytest.raises((ValueError, TypeError)):
            service.create({{"invalid": "data"}})
            
        # æµ‹è¯•ä¸å­˜åœ¨IDå¤„ç†
        result = service.get_by_id(99999)
        assert result is None
        
        # æµ‹è¯•åˆ é™¤ä¸å­˜åœ¨é¡¹ç›®
        delete_result = service.delete(99999)
        assert delete_result is False
        
    @pytest.mark.parametrize("test_scenario,expected_result", [
        ("valid_create", True),
        ("valid_update", True),
        ("valid_delete", True),
    ])
    def test_{module_name}_scenarios(self, test_scenario, expected_result, unit_test_db: Session):
        """å‚æ•°åŒ–æµ‹è¯•{module_name}åœºæ™¯"""
        service = {module_name.title()}Service(unit_test_db)
        
        if test_scenario == "valid_create":
            result = service.create(self.{module_name}_data)
            assert (result is not None) == expected_result
            
        elif test_scenario == "valid_update":
            created = service.create(self.{module_name}_data)
            result = service.update(created.id, {{"status": "updated"}})
            assert (result is not None) == expected_result
            
        elif test_scenario == "valid_delete":
            created = service.create(self.{module_name}_data)
            result = service.delete(created.id)
            assert result == expected_result
'''

    def generate_integration_tests(self, module_name: str) -> Dict[str, str]:
        """ç”Ÿæˆé›†æˆæµ‹è¯• (20% - MySQL Docker)"""
        integration_tests = self._generate_integration_api_tests(module_name)
        
        return {
            f'tests/integration/test_{module_name}_integration.py': integration_tests
        }
    
    def _generate_integration_api_tests(self, module_name: str) -> str:
        """ç”Ÿæˆé›†æˆAPIæµ‹è¯• - MySQL Dockeræ•°æ®åº“"""
        return f'''"""
{module_name.title()} é›†æˆæµ‹è¯•å¥—ä»¶

æµ‹è¯•ç±»å‹: é›†æˆæµ‹è¯• (Integration)
æ•°æ®ç­–ç•¥: MySQL Docker, mysql_integration_db fixture  
ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

æ ¹æ®testing-standards.mdç¬¬105-125è¡Œé›†æˆæµ‹è¯•è§„èŒƒ
"""

import pytest
import requests
from sqlalchemy.orm import Session

# æµ‹è¯•å·¥å‚å¯¼å…¥
from tests.factories import {module_name.title()}Factory, UserFactory

# Fixtureå¯¼å…¥
from tests.conftest import mysql_integration_db, api_client

# è¢«æµ‹æ¨¡å—å¯¼å…¥  
from app.modules.{module_name}.service import {module_name.title()}Service


@pytest.mark.integration
class Test{module_name.title()}Integration:
    """é›†æˆæµ‹è¯• - çœŸå®ç¯å¢ƒæ¨¡æ‹Ÿ"""
    
    def setup_method(self):
        """é›†æˆæµ‹è¯•å‡†å¤‡"""
        self.api_base_url = "http://localhost:8000"
        self.test_data = {module_name.title()}Factory.build_dict()
        
    def test_{module_name}_api_integration(self, api_client, mysql_integration_db: Session):
        """æµ‹è¯•{module_name} APIå®Œæ•´é›†æˆ"""
        # åˆ›å»ºAPIè¯·æ±‚
        create_response = api_client.post(
            f"/{module_name}/",
            json=self.test_data
        )
        
        # éªŒè¯åˆ›å»ºå“åº”
        assert create_response.status_code == 201
        created_data = create_response.json()
        assert "id" in created_data
        {module_name}_id = created_data["id"]
        
        # æŸ¥è¯¢APIéªŒè¯
        get_response = api_client.get(f"/{module_name}/{{poll_id}}")
        assert get_response.status_code == 200
        
        # æ›´æ–°APIéªŒè¯
        update_data = {{"status": "updated"}}
        update_response = api_client.put(
            f"/{module_name}/{{poll_id}}",
            json=update_data
        )
        assert update_response.status_code == 200
        
        # åˆ é™¤APIéªŒè¯
        delete_response = api_client.delete(f"/{module_name}/{{poll_id}}")
        assert delete_response.status_code == 204
        
    def test_{module_name}_database_integration(self, mysql_integration_db: Session):
        """æµ‹è¯•{module_name}æ•°æ®åº“é›†æˆ"""
        service = {module_name.title()}Service(mysql_integration_db)
        
        # æµ‹è¯•æ•°æ®åº“äº‹åŠ¡å®Œæ•´æ€§
        created = service.create(self.test_data)
        assert created is not None
        
        # éªŒè¯æ•°æ®åº“æŒä¹…åŒ–
        mysql_integration_db.commit()
        found = service.get_by_id(created.id)
        assert found is not None
        assert found.id == created.id
        
    def test_{module_name}_external_service_integration(self, mysql_integration_db: Session):
        """æµ‹è¯•{module_name}å¤–éƒ¨æœåŠ¡é›†æˆ"""
        service = {module_name.title()}Service(mysql_integration_db)
        
        # æ¨¡æ‹Ÿå¤–éƒ¨æœåŠ¡è°ƒç”¨
        with pytest.raises((ConnectionError, TimeoutError), match="external"):
            # è¿™é‡Œåº”è¯¥æ˜¯çœŸå®çš„å¤–éƒ¨æœåŠ¡è°ƒç”¨æµ‹è¯•
            pass
            
    @pytest.mark.slow
    def test_{module_name}_performance_integration(self, mysql_integration_db: Session):
        """æµ‹è¯•{module_name}æ€§èƒ½é›†æˆ"""
        service = {module_name.title()}Service(mysql_integration_db)
        
        import time
        start_time = time.time()
        
        # æ‰¹é‡æ“ä½œæ€§èƒ½æµ‹è¯•
        for i in range(100):
            test_data = {module_name.title()}Factory.build_dict()
            service.create(test_data)
            
        end_time = time.time()
        execution_time = end_time - start_time
        
        # éªŒè¯æ€§èƒ½è¦æ±‚ (100ä¸ªæ“ä½œ < 5ç§’)
        assert execution_time < 5.0, f"Performance test failed: {{execution_time:.2f}}s > 5s"
'''

    def generate_smoke_tests(self, module_name: str) -> Dict[str, str]:
        """ç”ŸæˆçƒŸé›¾æµ‹è¯• (2% - SQLiteæ–‡ä»¶)"""
        smoke_tests = self._generate_smoke_health_tests(module_name)
        
        return {
            f'tests/smoke/test_{module_name}_smoke.py': smoke_tests
        }
    
    def _generate_smoke_health_tests(self, module_name: str) -> str:
        """ç”ŸæˆçƒŸé›¾æµ‹è¯• - SQLiteæ–‡ä»¶æ•°æ®åº“"""
        return f'''"""
{module_name.title()} çƒŸé›¾æµ‹è¯•å¥—ä»¶

æµ‹è¯•ç±»å‹: çƒŸé›¾æµ‹è¯• (Smoke)
æ•°æ®ç­–ç•¥: SQLiteæ–‡ä»¶æ•°æ®åº“, smoke_test_db fixture
ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

æ ¹æ®testing-standards.mdç¬¬95-104è¡ŒçƒŸé›¾æµ‹è¯•è§„èŒƒ
"""

import pytest
import requests
from sqlalchemy.orm import Session

# Fixtureå¯¼å…¥
from tests.conftest import smoke_test_db


@pytest.mark.smoke  
class Test{module_name.title()}Smoke:
    """çƒŸé›¾æµ‹è¯• - åŸºæœ¬å¥åº·æ£€æŸ¥"""
    
    def test_{module_name}_health_check(self):
        """éªŒè¯{module_name}æ¨¡å—åŸºæœ¬å¥åº·çŠ¶æ€"""
        try:
            # æ¨¡å—å¯¼å…¥æµ‹è¯•
            from app.modules.{module_name} import service
            from app.modules.{module_name} import models
            assert True, "{module_name} module imports successfully"
        except ImportError as e:
            pytest.fail(f"{module_name} module import failed: {{e}}")
            
    def test_{module_name}_database_connection_smoke(self, smoke_test_db: Session):
        """éªŒè¯{module_name}æ•°æ®åº“è¿æ¥æ­£å¸¸"""
        # ç®€å•çš„æ•°æ®åº“è¿æ¥æµ‹è¯•
        result = smoke_test_db.execute("SELECT 1 as test")
        assert result.fetchone()[0] == 1
        
    def test_{module_name}_api_endpoint_smoke(self):
        """éªŒè¯{module_name} APIç«¯ç‚¹å¯è®¿é—®æ€§"""
        try:
            response = requests.get(
                "http://localhost:8000/{module_name}/health",
                timeout=5
            )
            assert response.status_code in [200, 404]  # 404ä¹Ÿå¯æ¥å—ï¼Œåªè¦æœåŠ¡å“åº”
        except requests.ConnectionError:
            pytest.skip("APIæœåŠ¡æœªè¿è¡Œï¼Œè·³è¿‡çƒŸé›¾æµ‹è¯•")
            
    def test_{module_name}_basic_functionality_smoke(self, smoke_test_db: Session):
        """éªŒè¯{module_name}åŸºæœ¬åŠŸèƒ½æ­£å¸¸"""
        from app.modules.{module_name}.service import {module_name.title()}Service
        
        service = {module_name.title()}Service(smoke_test_db)
        
        # æœ€åŸºæœ¬çš„åŠŸèƒ½æµ‹è¯•
        basic_data = {{"name": "smoke_test", "status": "active"}}
        
        try:
            created = service.create(basic_data)
            assert created is not None
        except Exception as e:
            pytest.fail(f"{module_name} basic create functionality failed: {{e}}")
'''

    def generate_e2e_tests(self, module_name: str) -> Dict[str, str]:
        """ç”ŸæˆE2Eæµ‹è¯• (6% - MySQL Docker)"""
        e2e_tests = self._generate_e2e_workflow_tests(module_name)
        
        return {
            f'tests/e2e/test_{module_name}_e2e.py': e2e_tests
        }
    
    def _generate_e2e_workflow_tests(self, module_name: str) -> str:
        """ç”ŸæˆE2Eå·¥ä½œæµæµ‹è¯• - MySQL Dockeræ•°æ®åº“"""
        return f'''"""
{module_name.title()} E2Eæµ‹è¯•å¥—ä»¶

æµ‹è¯•ç±»å‹: ç«¯åˆ°ç«¯æµ‹è¯• (E2E)
æ•°æ®ç­–ç•¥: MySQL Docker, mysql_e2e_db fixture
ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

æ ¹æ®testing-standards.mdç¬¬135-155è¡ŒE2Eæµ‹è¯•è§„èŒƒ
"""

import pytest
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from sqlalchemy.orm import Session

# æµ‹è¯•å·¥å‚å¯¼å…¥
from tests.factories import {module_name.title()}Factory, UserFactory

# Fixtureå¯¼å…¥
from tests.conftest import mysql_e2e_db, selenium_driver


@pytest.mark.e2e
@pytest.mark.slow
class Test{module_name.title()}E2E:
    """ç«¯åˆ°ç«¯æµ‹è¯• - å®Œæ•´ç”¨æˆ·æµç¨‹"""
    
    def setup_method(self):
        """E2Eæµ‹è¯•å‡†å¤‡"""
        self.base_url = "http://localhost:3000"  # å‰ç«¯åº”ç”¨URL
        self.test_user_data = UserFactory.build_dict()
        self.test_{module_name}_data = {module_name.title()}Factory.build_dict()
        
    def test_complete_{module_name}_user_journey(self, selenium_driver, mysql_e2e_db: Session):
        """æµ‹è¯•{module_name}å®Œæ•´ç”¨æˆ·æ—…ç¨‹"""
        driver = selenium_driver
        
        # æ­¥éª¤1: ç”¨æˆ·ç™»å½•
        driver.get(f"{{self.base_url}}/login")
        
        # è¾“å…¥ç™»å½•ä¿¡æ¯
        username_field = WebDriverWait(driver, 10).until(
            EC.presence_of_element_located((By.ID, "username"))
        )
        password_field = driver.find_element(By.ID, "password")
        login_button = driver.find_element(By.ID, "login-btn")
        
        username_field.send_keys(self.test_user_data["username"])
        password_field.send_keys(self.test_user_data["password"])
        login_button.click()
        
        # éªŒè¯ç™»å½•æˆåŠŸ
        WebDriverWait(driver, 10).until(
            EC.presence_of_element_located((By.ID, "dashboard"))
        )
        
        # æ­¥éª¤2: å¯¼èˆªåˆ°{module_name}é¡µé¢
        driver.get(f"{{self.base_url}}/{module_name}")
        
        # æ­¥éª¤3: åˆ›å»ºæ–°{module_name}
        create_button = WebDriverWait(driver, 10).until(
            EC.element_to_be_clickable((By.ID, f"create-{module_name}-btn"))
        )
        create_button.click()
        
        # å¡«å†™è¡¨å•
        name_field = driver.find_element(By.ID, f"{module_name}-name")
        name_field.send_keys(self.test_{module_name}_data["name"])
        
        submit_button = driver.find_element(By.ID, "submit-btn")
        submit_button.click()
        
        # æ­¥éª¤4: éªŒè¯åˆ›å»ºæˆåŠŸ
        success_message = WebDriverWait(driver, 10).until(
            EC.presence_of_element_located((By.CLASS_NAME, "success-message"))
        )
        assert "successfully created" in success_message.text.lower()
        
        # æ­¥éª¤5: éªŒè¯æ•°æ®åº“ä¸­å­˜åœ¨
        from app.modules.{module_name}.service import {module_name.title()}Service
        service = {module_name.title()}Service(mysql_e2e_db)
        
        created_items = service.get_all()
        assert len(created_items) > 0
        assert any(item.name == self.test_{module_name}_data["name"] for item in created_items)
        
    def test_{module_name}_error_handling_e2e(self, selenium_driver, mysql_e2e_db: Session):
        """æµ‹è¯•{module_name}é”™è¯¯å¤„ç†ç«¯åˆ°ç«¯æµç¨‹"""
        driver = selenium_driver
        
        # å¯¼èˆªåˆ°{module_name}é¡µé¢
        driver.get(f"{{self.base_url}}/{module_name}")
        
        # å°è¯•æäº¤æ— æ•ˆè¡¨å•
        create_button = WebDriverWait(driver, 10).until(
            EC.element_to_be_clickable((By.ID, f"create-{module_name}-btn"))
        )
        create_button.click()
        
        # ä¸å¡«å†™å¿…å¡«å­—æ®µï¼Œç›´æ¥æäº¤
        submit_button = driver.find_element(By.ID, "submit-btn")
        submit_button.click()
        
        # éªŒè¯é”™è¯¯æ¶ˆæ¯æ˜¾ç¤º
        error_message = WebDriverWait(driver, 10).until(
            EC.presence_of_element_located((By.CLASS_NAME, "error-message"))
        )
        assert "required" in error_message.text.lower()
'''

    def generate_specialized_tests(self, module_name: str) -> Dict[str, str]:
        """ç”Ÿæˆä¸“é¡¹æµ‹è¯• (2% - æ€§èƒ½/å®‰å…¨)"""
        performance_tests = self._generate_performance_tests(module_name)
        security_tests = self._generate_security_tests(module_name)
        
        return {
            f'tests/performance/test_{module_name}_performance.py': performance_tests,
            f'tests/security/test_{module_name}_security.py': security_tests
        }
    
    def _generate_performance_tests(self, module_name: str) -> str:
        """ç”Ÿæˆæ€§èƒ½æµ‹è¯•"""
        return f'''"""
{module_name.title()} æ€§èƒ½æµ‹è¯•å¥—ä»¶

æµ‹è¯•ç±»å‹: ä¸“é¡¹æµ‹è¯• (Performance)
ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

æ ¹æ®testing-standards.mdç¬¬165-185è¡Œæ€§èƒ½æµ‹è¯•è§„èŒƒ
"""

import pytest
import time
import threading
from concurrent.futures import ThreadPoolExecutor
from sqlalchemy.orm import Session

# æµ‹è¯•å·¥å‚å¯¼å…¥
from tests.factories import {module_name.title()}Factory

# Fixtureå¯¼å…¥
from tests.conftest import mysql_integration_db

# è¢«æµ‹æ¨¡å—å¯¼å…¥
from app.modules.{module_name}.service import {module_name.title()}Service


@pytest.mark.performance
@pytest.mark.slow
class Test{module_name.title()}Performance:
    """æ€§èƒ½æµ‹è¯•"""
    
    def test_{module_name}_create_performance(self, mysql_integration_db: Session):
        """æµ‹è¯•{module_name}åˆ›å»ºæ“ä½œæ€§èƒ½"""
        service = {module_name.title()}Service(mysql_integration_db)
        
        # æ€§èƒ½åŸºå‡†: 1000æ¬¡åˆ›å»ºæ“ä½œ < 10ç§’
        start_time = time.time()
        
        for i in range(1000):
            test_data = {module_name.title()}Factory.build_dict()
            test_data['name'] = f"perf_test_{{i}}"
            service.create(test_data)
            
        end_time = time.time()
        execution_time = end_time - start_time
        
        assert execution_time < 10.0, f"Create performance failed: {{execution_time:.2f}}s > 10s"
        
    def test_{module_name}_query_performance(self, mysql_integration_db: Session):
        """æµ‹è¯•{module_name}æŸ¥è¯¢æ“ä½œæ€§èƒ½"""
        service = {module_name.title()}Service(mysql_integration_db)
        
        # å‡†å¤‡æµ‹è¯•æ•°æ®
        for i in range(100):
            test_data = {module_name.title()}Factory.build_dict()
            test_data['name'] = f"query_test_{{i}}"
            service.create(test_data)
            
        # æ€§èƒ½æµ‹è¯•: 1000æ¬¡æŸ¥è¯¢ < 5ç§’
        start_time = time.time()
        
        for i in range(1000):
            results = service.get_all(limit=10)
            assert len(results) > 0
            
        end_time = time.time()
        execution_time = end_time - start_time
        
        assert execution_time < 5.0, f"Query performance failed: {{execution_time:.2f}}s > 5s"
        
    def test_{module_name}_concurrent_access(self, mysql_integration_db: Session):
        """æµ‹è¯•{module_name}å¹¶å‘è®¿é—®æ€§èƒ½"""
        service = {module_name.title()}Service(mysql_integration_db)
        
        def create_item(thread_id):
            test_data = {module_name.title()}Factory.build_dict()
            test_data['name'] = f"concurrent_test_{{thread_id}}"
            return service.create(test_data)
            
        # å¹¶å‘æµ‹è¯•: 10ä¸ªçº¿ç¨‹åŒæ—¶åˆ›å»º100ä¸ªé¡¹ç›®
        start_time = time.time()
        
        with ThreadPoolExecutor(max_workers=10) as executor:
            futures = [executor.submit(create_item, i) for i in range(100)]
            results = [f.result() for f in futures]
            
        end_time = time.time()
        execution_time = end_time - start_time
        
        # éªŒè¯æ‰€æœ‰æ“ä½œæˆåŠŸ
        assert all(r is not None for r in results)
        
        # å¹¶å‘æ€§èƒ½è¦æ±‚: 100ä¸ªå¹¶å‘æ“ä½œ < 15ç§’
        assert execution_time < 15.0, f"Concurrent performance failed: {{execution_time:.2f}}s > 15s"
'''
    
    def _generate_security_tests(self, module_name: str) -> str:
        """ç”Ÿæˆå®‰å…¨æµ‹è¯•"""
        return f'''"""
{module_name.title()} å®‰å…¨æµ‹è¯•å¥—ä»¶

æµ‹è¯•ç±»å‹: ä¸“é¡¹æµ‹è¯• (Security)
ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

æ ¹æ®testing-standards.mdç¬¬190-210è¡Œå®‰å…¨æµ‹è¯•è§„èŒƒ
"""

import pytest
import requests
from sqlalchemy.orm import Session

# æµ‹è¯•å·¥å‚å¯¼å…¥
from tests.factories import {module_name.title()}Factory, UserFactory

# Fixtureå¯¼å…¥
from tests.conftest import mysql_integration_db, api_client


@pytest.mark.security
class Test{module_name.title()}Security:
    """å®‰å…¨æµ‹è¯•"""
    
    def test_{module_name}_sql_injection_protection(self, api_client):
        """æµ‹è¯•{module_name} SQLæ³¨å…¥é˜²æŠ¤"""
        # SQLæ³¨å…¥æ”»å‡»æµ‹è¯•
        malicious_payloads = [
            "'; DROP TABLE users; --",
            "1' OR '1'='1",
            "1; INSERT INTO users VALUES('hacker', 'password'); --"
        ]
        
        for payload in malicious_payloads:
            response = api_client.get(f"/{module_name}/{{payload}}")
            
            # éªŒè¯æ²¡æœ‰è¿”å›æ•æ„Ÿæ•°æ®æˆ–ç³»ç»Ÿé”™è¯¯
            assert response.status_code in [400, 404, 422]
            assert "error" not in response.text.lower() or "sql" not in response.text.lower()
            
    def test_{module_name}_xss_protection(self, api_client):
        """æµ‹è¯•{module_name} XSSé˜²æŠ¤"""
        xss_payloads = [
            "<script>alert('xss')</script>",
            "javascript:alert('xss')",
            "<img src=x onerror=alert('xss')>"
        ]
        
        for payload in xss_payloads:
            test_data = {module_name.title()}Factory.build_dict()
            test_data['name'] = payload
            
            response = api_client.post(f"/{module_name}/", json=test_data)
            
            if response.status_code == 201:
                # å¦‚æœåˆ›å»ºæˆåŠŸï¼ŒéªŒè¯è¿”å›çš„æ•°æ®å·²è¢«è½¬ä¹‰
                response_text = response.text
                assert "<script>" not in response_text
                assert "javascript:" not in response_text
                
    def test_{module_name}_authorization_check(self, api_client):
        """æµ‹è¯•{module_name}æƒé™æ§åˆ¶"""
        # æœªæˆæƒè®¿é—®æµ‹è¯•
        response = api_client.get(f"/{module_name}/")
        
        # æ ¹æ®å®é™…æƒé™è®¾è®¡éªŒè¯
        if response.status_code == 401:
            assert "unauthorized" in response.text.lower()
        elif response.status_code == 403:
            assert "forbidden" in response.text.lower()
            
    def test_{module_name}_input_validation(self, api_client):
        """æµ‹è¯•{module_name}è¾“å…¥éªŒè¯"""
        # æ— æ•ˆè¾“å…¥æµ‹è¯•
        invalid_payloads = [
            {{"name": ""}},  # ç©ºå€¼
            {{"name": "x" * 1000}},  # è¶…é•¿å€¼
            {{"invalid_field": "test"}},  # æ— æ•ˆå­—æ®µ
            {{}},  # ç©ºå¯¹è±¡
        ]
        
        for payload in invalid_payloads:
            response = api_client.post(f"/{module_name}/", json=payload)
            
            # éªŒè¯è¾“å…¥éªŒè¯ç”Ÿæ•ˆ
            assert response.status_code in [400, 422]
            
    def test_{module_name}_rate_limiting(self, api_client):
        """æµ‹è¯•{module_name}é€Ÿç‡é™åˆ¶"""
        # å¿«é€Ÿè¿ç»­è¯·æ±‚æµ‹è¯•
        responses = []
        
        for i in range(100):  # å‘é€100ä¸ªå¿«é€Ÿè¯·æ±‚
            response = api_client.get(f"/{module_name}/")
            responses.append(response.status_code)
            
        # éªŒè¯æ˜¯å¦æœ‰é€Ÿç‡é™åˆ¶ç”Ÿæ•ˆ
        rate_limited = any(status == 429 for status in responses)
        
        # å¦‚æœæ²¡æœ‰é€Ÿç‡é™åˆ¶ï¼Œè‡³å°‘éªŒè¯æœåŠ¡ç¨³å®šæ€§
        if not rate_limited:
            successful_requests = sum(1 for status in responses if status == 200)
            assert successful_requests > 50, "æœåŠ¡åœ¨é«˜é¢‘è¯·æ±‚ä¸‹ä¸ç¨³å®š"
'''

    def generate_all_tests(self, module_name: str) -> Dict[str, str]:
        """ç”Ÿæˆå®Œæ•´çš„äº”å±‚æµ‹è¯•å¥—ä»¶"""
        all_tests = {}
        
        # 70% å•å…ƒæµ‹è¯•
        unit_tests = self.generate_unit_tests(module_name)
        all_tests.update(unit_tests)
        
        # 20% é›†æˆæµ‹è¯•  
        integration_tests = self.generate_integration_tests(module_name)
        all_tests.update(integration_tests)
        
        # 6% E2Eæµ‹è¯•
        e2e_tests = self.generate_e2e_tests(module_name)
        all_tests.update(e2e_tests)
        
        # 2% çƒŸé›¾æµ‹è¯•
        smoke_tests = self.generate_smoke_tests(module_name)
        all_tests.update(smoke_tests)
        
        # 2% ä¸“é¡¹æµ‹è¯•
        specialized_tests = self.generate_specialized_tests(module_name)
        all_tests.update(specialized_tests)
        
        return all_tests
    
    def create_test_files(self, test_files: Dict[str, str]) -> None:
        """åˆ›å»ºæµ‹è¯•æ–‡ä»¶åˆ°ç£ç›˜"""
        for file_path, content in test_files.items():
            full_path = self.project_root / file_path
            
            # ç¡®ä¿ç›®å½•å­˜åœ¨
            full_path.parent.mkdir(parents=True, exist_ok=True)
            
            # å†™å…¥æ–‡ä»¶
            with open(full_path, 'w', encoding='utf-8') as f:
                f.write(content)
                
            print(f"âœ… Created: {file_path}")
    
    def validate_module_exists(self, module_name: str) -> bool:
        """éªŒè¯æ¨¡å—æ˜¯å¦å­˜åœ¨"""
        module_path = self.project_root / "app" / "modules" / module_name
        return module_path.exists()


class TestCodeValidator:
    """æµ‹è¯•ä»£ç è‡ªåŠ¨åŒ–éªŒè¯å™¨"""
    
    def __init__(self, project_root: Path):
        self.project_root = project_root
        self.validation_results = []
        
    def validate_generated_tests(self, test_files: Dict[str, str]) -> Dict[str, Any]:
        """éªŒè¯ç”Ÿæˆçš„æµ‹è¯•ä»£ç """
        validation_report = {
            'total_files': len(test_files),
            'passed': 0,
            'failed': 0,
            'warnings': 0,
            'details': {}
        }
        
        for file_path, content in test_files.items():
            print(f"ğŸ” éªŒè¯æ–‡ä»¶: {file_path}")
            
            file_validation = self._validate_single_file(file_path, content)
            validation_report['details'][file_path] = file_validation
            
            if file_validation['status'] == 'passed':
                validation_report['passed'] += 1
            elif file_validation['status'] == 'failed':
                validation_report['failed'] += 1
            else:
                validation_report['warnings'] += 1
                
        return validation_report
    
    def _validate_single_file(self, file_path: str, content: str) -> Dict[str, Any]:
        """éªŒè¯å•ä¸ªæµ‹è¯•æ–‡ä»¶"""
        validation = {
            'status': 'passed',
            'issues': [],
            'suggestions': [],
            'metrics': {}
        }
        
        # 1. è¯­æ³•æ£€æŸ¥
        syntax_issues = self._check_syntax(content)
        if syntax_issues:
            validation['issues'].extend(syntax_issues)
            validation['status'] = 'failed'
            
        # 2. å¯¼å…¥éªŒè¯
        import_issues = self._check_imports(content)
        if import_issues:
            validation['issues'].extend(import_issues)
            validation['status'] = 'failed'
            
        # 3. Factory Boyæ¨¡å¼éªŒè¯
        factory_issues = self._check_factory_pattern(content)
        if factory_issues:
            validation['suggestions'].extend(factory_issues)
            if validation['status'] == 'passed':
                validation['status'] = 'warning'
                
        # 4. pytestæ ‡å‡†éªŒè¯
        pytest_issues = self._check_pytest_standards(content)
        if pytest_issues:
            validation['suggestions'].extend(pytest_issues)
            
        # 5. æµ‹è¯•è¦†ç›–åº¦åˆ†æ
        validation['metrics'] = self._analyze_test_metrics(content)
        
        # 6. æ–‡æ¡£å­—ç¬¦ä¸²éªŒè¯
        docstring_issues = self._check_docstrings(content)
        if docstring_issues:
            validation['suggestions'].extend(docstring_issues)
            
        return validation
    
    def _check_syntax(self, content: str) -> List[str]:
        """æ£€æŸ¥Pythonè¯­æ³•"""
        issues = []
        try:
            compile(content, '<generated_test>', 'exec')
        except SyntaxError as e:
            issues.append(f"è¯­æ³•é”™è¯¯ ç¬¬{e.lineno}è¡Œ: {e.msg}")
        except Exception as e:
            issues.append(f"ç¼–è¯‘é”™è¯¯: {str(e)}")
        return issues
    
    def _check_imports(self, content: str) -> List[str]:
        """æ£€æŸ¥å¯¼å…¥è¯­å¥"""
        issues = []
        lines = content.split('\n')
        
        required_imports = {
            'pytest': False,
            'Factory': False,
            'Session': False
        }
        
        for line in lines:
            line = line.strip()
            if line.startswith('import pytest'):
                required_imports['pytest'] = True
            if 'Factory' in line and 'from tests.factories' in line:
                required_imports['Factory'] = True  
            if 'Session' in line and 'sqlalchemy' in line:
                required_imports['Session'] = True
                
        for import_name, found in required_imports.items():
            if not found and import_name in content:
                issues.append(f"ç¼ºå°‘å¿…éœ€å¯¼å…¥: {import_name}")
                
        return issues
    
    def _check_factory_pattern(self, content: str) -> List[str]:
        """æ£€æŸ¥Factory Boyæ¨¡å¼ä½¿ç”¨"""
        suggestions = []
        
        # æ£€æŸ¥æ˜¯å¦ä½¿ç”¨Factory.build()æˆ–Factory.create()
        if 'Factory' in content:
            if '.build()' not in content and '.create()' not in content:
                suggestions.append("å»ºè®®ä½¿ç”¨Factory.build()æˆ–Factory.create()æ–¹æ³•")
                
            if '.build_dict()' not in content and '.create_dict()' not in content:
                suggestions.append("å»ºè®®ä½¿ç”¨Factory.build_dict()ç”Ÿæˆå­—å…¸æ•°æ®")
                
        return suggestions
    
    def _check_pytest_standards(self, content: str) -> List[str]:
        """æ£€æŸ¥pytestæ ‡å‡†"""
        suggestions = []
        lines = content.split('\n')
        
        test_methods = [line for line in lines if 'def test_' in line]
        
        # æ£€æŸ¥æµ‹è¯•æ–¹æ³•å‘½å
        for line in test_methods:
            if 'def test_' in line:
                method_name = line.split('def ')[1].split('(')[0]
                if len(method_name) < 15:
                    suggestions.append(f"æµ‹è¯•æ–¹æ³•åè¿‡çŸ­ï¼Œå»ºè®®æ›´å…·æè¿°æ€§: {method_name}")
                    
        # æ£€æŸ¥æ–­è¨€è¯­å¥
        assert_count = content.count('assert ')
        if assert_count < len(test_methods):
            suggestions.append("éƒ¨åˆ†æµ‹è¯•æ–¹æ³•å¯èƒ½ç¼ºå°‘æ–­è¨€è¯­å¥")
            
        # æ£€æŸ¥æ–‡æ¡£å­—ç¬¦ä¸²
        docstring_count = content.count('"""')
        if docstring_count < len(test_methods) * 2:  # æ¯ä¸ªæ–¹æ³•è‡³å°‘åº”è¯¥æœ‰ä¸€ä¸ªdocstring
            suggestions.append("å»ºè®®ä¸ºæ‰€æœ‰æµ‹è¯•æ–¹æ³•æ·»åŠ æ–‡æ¡£å­—ç¬¦ä¸²")
            
        return suggestions
    
    def _analyze_test_metrics(self, content: str) -> Dict[str, int]:
        """åˆ†ææµ‹è¯•åº¦é‡æŒ‡æ ‡"""
        return {
            'test_methods': content.count('def test_'),
            'assert_statements': content.count('assert '),
            'mock_usage': content.count('Mock()') + content.count('mocker.'),
            'parametrized_tests': content.count('@pytest.mark.parametrize'),
            'fixtures_used': content.count('def test_') if 'fixture' in content else 0,
            'lines_of_code': len(content.split('\n'))
        }
    
    def _check_docstrings(self, content: str) -> List[str]:
        """æ£€æŸ¥æ–‡æ¡£å­—ç¬¦ä¸²è´¨é‡"""
        suggestions = []
        lines = content.split('\n')
        
        in_method = False
        method_has_docstring = False
        
        for i, line in enumerate(lines):
            if 'def test_' in line:
                in_method = True
                method_has_docstring = False
            elif in_method and '"""' in line:
                method_has_docstring = True
            elif in_method and (line.strip().startswith('def ') or i == len(lines) - 1):
                if not method_has_docstring:
                    method_name = lines[i-1].split('def ')[1].split('(')[0] if i > 0 else "unknown"
                    suggestions.append(f"æ–¹æ³•ç¼ºå°‘æ–‡æ¡£å­—ç¬¦ä¸²: {method_name}")
                in_method = False
                
        return suggestions
    
    def print_validation_report(self, report: Dict[str, Any]) -> None:
        """æ‰“å°éªŒè¯æŠ¥å‘Š"""
        print("\n" + "=" * 60)
        print("ğŸ” æµ‹è¯•ä»£ç éªŒè¯æŠ¥å‘Š")
        print("=" * 60)
        
        print(f"ğŸ“Š æ€»ä½“ç»Ÿè®¡:")
        print(f"   â€¢ æ€»æ–‡ä»¶æ•°: {report['total_files']}")
        print(f"   â€¢ é€šè¿‡éªŒè¯: {report['passed']} âœ…")
        print(f"   â€¢ éªŒè¯å¤±è´¥: {report['failed']} âŒ")  
        print(f"   â€¢ è­¦å‘Šæç¤º: {report['warnings']} âš ï¸")
        
        if report['failed'] > 0:
            print(f"\nâŒ éªŒè¯å¤±è´¥çš„æ–‡ä»¶:")
            for file_path, details in report['details'].items():
                if details['status'] == 'failed':
                    print(f"   ğŸ“ {file_path}")
                    for issue in details['issues']:
                        print(f"      â€¢ {issue}")
                        
        if report['warnings'] > 0:
            print(f"\nâš ï¸  éœ€è¦æ³¨æ„çš„æ–‡ä»¶:")
            for file_path, details in report['details'].items():
                if details['status'] == 'warning':
                    print(f"   ğŸ“ {file_path}")
                    for suggestion in details['suggestions']:
                        print(f"      â€¢ {suggestion}")
                        
        # æ˜¾ç¤ºåº¦é‡æŒ‡æ ‡
        print(f"\nğŸ“ˆ ä»£ç åº¦é‡æŒ‡æ ‡:")
        total_metrics = {
            'test_methods': 0,
            'assert_statements': 0,
            'mock_usage': 0,
            'parametrized_tests': 0,
            'lines_of_code': 0
        }
        
        for details in report['details'].values():
            for key, value in details['metrics'].items():
                if key in total_metrics:
                    total_metrics[key] += value
                    
        print(f"   â€¢ æµ‹è¯•æ–¹æ³•æ€»æ•°: {total_metrics['test_methods']}")
        print(f"   â€¢ æ–­è¨€è¯­å¥æ€»æ•°: {total_metrics['assert_statements']}")
        print(f"   â€¢ Mockä½¿ç”¨æ¬¡æ•°: {total_metrics['mock_usage']}")
        print(f"   â€¢ å‚æ•°åŒ–æµ‹è¯•: {total_metrics['parametrized_tests']}")
        print(f"   â€¢ ä»£ç æ€»è¡Œæ•°: {total_metrics['lines_of_code']}")
        
        if total_metrics['test_methods'] > 0:
            avg_assertions = total_metrics['assert_statements'] / total_metrics['test_methods']
            print(f"   â€¢ å¹³å‡æ¯æµ‹è¯•æ–­è¨€æ•°: {avg_assertions:.1f}")
            
        return report['failed'] == 0


def main():
    """ä¸»å‡½æ•° - å‘½ä»¤è¡Œæ¥å£"""
    parser = argparse.ArgumentParser(
        description="äº”å±‚æ¶æ„æ ‡å‡†æµ‹è¯•ç”Ÿæˆå™¨",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹ç”¨æ³•:
  python scripts/generate_test_template.py user_auth --type all
  python scripts/generate_test_template.py shopping_cart --type unit  
  python scripts/generate_test_template.py inventory --type integration
  
æµ‹è¯•ç±»å‹è¯´æ˜:
  all          - ç”Ÿæˆå®Œæ•´äº”å±‚æµ‹è¯•å¥—ä»¶ (æ¨è)
  unit         - ä»…ç”Ÿæˆå•å…ƒæµ‹è¯• (70%)
  integration  - ä»…ç”Ÿæˆé›†æˆæµ‹è¯• (20%)  
  e2e          - ä»…ç”ŸæˆE2Eæµ‹è¯• (6%)
  smoke        - ä»…ç”ŸæˆçƒŸé›¾æµ‹è¯• (2%)
  specialized  - ä»…ç”Ÿæˆä¸“é¡¹æµ‹è¯• (2%)
        """
    )
    
    parser.add_argument(
        "module_name",
        help="æ¨¡å—åç§° (å¦‚: user_auth, shopping_cart)"
    )
    
    parser.add_argument(
        "--type", "-t",
        choices=["all", "unit", "integration", "e2e", "smoke", "specialized"],
        default="all",
        help="æµ‹è¯•ç±»å‹ (é»˜è®¤: all)"
    )
    
    parser.add_argument(
        "--validate", "-v",
        action="store_true",
        help="éªŒè¯æ¨¡å—æ˜¯å¦å­˜åœ¨"
    )
    
    parser.add_argument(
        "--auto-validate",
        action="store_true",
        help="è‡ªåŠ¨éªŒè¯ç”Ÿæˆçš„æµ‹è¯•ä»£ç è´¨é‡"
    )
    
    parser.add_argument(
        "--skip-create",
        action="store_true", 
        help="ä»…ç”Ÿæˆä»£ç ä½†ä¸åˆ›å»ºæ–‡ä»¶ï¼ˆç”¨äºéªŒè¯æµ‹è¯•ï¼‰"
    )
    
    args = parser.parse_args()
    
    # åˆ›å»ºç”Ÿæˆå™¨å®ä¾‹
    generator = FiveLayerTestGenerator()
    
    # éªŒè¯æ¨¡å—å­˜åœ¨æ€§
    if args.validate and not generator.validate_module_exists(args.module_name):
        print(f"âŒ æ¨¡å— '{args.module_name}' ä¸å­˜åœ¨äº app/modules/ ç›®å½•ä¸­")
        print(f"è¯·å…ˆåˆ›å»ºæ¨¡å—æˆ–æ£€æŸ¥æ¨¡å—åç§°æ‹¼å†™")
        return 1
    
    print(f"ğŸš€ å¼€å§‹ç”Ÿæˆ {args.module_name} æ¨¡å—çš„ {args.type} æµ‹è¯•...")
    print(f"ğŸ“‹ éµå¾ªæ ‡å‡†: docs/standards/testing-standards.md")
    print("=" * 60)
    
    # æ ¹æ®ç±»å‹ç”Ÿæˆæµ‹è¯•
    test_files = {}
    
    if args.type == "all":
        test_files = generator.generate_all_tests(args.module_name)
    elif args.type == "unit":
        test_files = generator.generate_unit_tests(args.module_name)
    elif args.type == "integration":
        test_files = generator.generate_integration_tests(args.module_name)
    elif args.type == "e2e":
        test_files = generator.generate_e2e_tests(args.module_name)
    elif args.type == "smoke":
        test_files = generator.generate_smoke_tests(args.module_name)
    elif args.type == "specialized":
        test_files = generator.generate_specialized_tests(args.module_name)
    
    # è‡ªåŠ¨éªŒè¯ç”Ÿæˆçš„ä»£ç ï¼ˆå¦‚æœå¯ç”¨ï¼‰
    validation_passed = True
    if args.auto_validate:
        print("\nğŸ” å¼€å§‹è‡ªåŠ¨éªŒè¯ç”Ÿæˆçš„æµ‹è¯•ä»£ç ...")
        validator = TestCodeValidator(generator.project_root)
        validation_report = validator.validate_generated_tests(test_files)
        validation_passed = validator.print_validation_report(validation_report)
        
        if not validation_passed:
            print("\nâŒ ä»£ç éªŒè¯å¤±è´¥! è¯·æ£€æŸ¥ä¸Šè¿°é—®é¢˜åå†åˆ›å»ºæ–‡ä»¶ã€‚")
            if not args.skip_create:
                print("æç¤º: ä½¿ç”¨ --skip-create å‚æ•°ä»…ç”Ÿæˆä»£ç è¿›è¡ŒéªŒè¯è€Œä¸åˆ›å»ºæ–‡ä»¶")
                return 1
    
    # åˆ›å»ºæµ‹è¯•æ–‡ä»¶ï¼ˆé™¤éè·³è¿‡ï¼‰
    if not args.skip_create:
        generator.create_test_files(test_files)
        print("=" * 60)
        print(f"âœ… å®Œæˆ! å·²ç”Ÿæˆ {len(test_files)} ä¸ªæµ‹è¯•æ–‡ä»¶")
    else:
        print("=" * 60)
        print(f"âœ… ä»£ç ç”Ÿæˆå®Œæˆ! (--skip-create æ¨¡å¼ï¼Œæœªåˆ›å»ºæ–‡ä»¶)")
        
    print(f"ğŸ“Š æµ‹è¯•åˆ†å¸ƒç¬¦åˆäº”å±‚æ¶æ„è¦æ±‚:")
    
    if args.type == "all":
        print("   â€¢ 70% å•å…ƒæµ‹è¯• (Mock + SQLiteå†…å­˜)")
        print("   â€¢ 20% é›†æˆæµ‹è¯• (MySQL Docker)")  
        print("   â€¢ 6% E2Eæµ‹è¯• (MySQL Docker)")
        print("   â€¢ 2% çƒŸé›¾æµ‹è¯• (SQLiteæ–‡ä»¶)")
        print("   â€¢ 2% ä¸“é¡¹æµ‹è¯• (æ€§èƒ½/å®‰å…¨)")
    
    print(f"\nğŸ§ª è¿è¡Œæµ‹è¯•å‘½ä»¤:")
    print(f"   pytest tests/unit/test_{args.module_name}_* -v")
    print(f"   pytest tests/integration/test_{args.module_name}_* -v")
    print(f"   pytest tests/smoke/test_{args.module_name}_* -v")
    
    return 0


if __name__ == "__main__":
    sys.exit(main())