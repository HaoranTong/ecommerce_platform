#!/usr/bin/env python3
"""
æ™ºèƒ½äº”å±‚æ¶æ„æµ‹è¯•ç”Ÿæˆå™¨ - å¢å¼ºç‰ˆ

é›†æˆæ™ºèƒ½æ¨¡å‹åˆ†æåŠŸèƒ½ï¼Œæ”¯æŒAST+è¿è¡Œæ—¶åŒé‡åˆ†æ
è‡ªåŠ¨ç”Ÿæˆå®Œæ•´çš„äº”å±‚æµ‹è¯•æ¶æ„ï¼š70%å•å…ƒã€20%é›†æˆã€6%E2Eã€2%çƒŸé›¾ã€2%ä¸“é¡¹

ä¸»è¦åŠŸèƒ½ï¼š
1. æ™ºèƒ½æ¨¡å‹åˆ†æ - è‡ªåŠ¨è§£æSQLAlchemyæ¨¡å‹ç»“æ„
2. æ™ºèƒ½æ•°æ®å·¥å‚ç”Ÿæˆ - åŸºäºæ¨¡å‹è‡ªåŠ¨ç”ŸæˆFactory Boyç±»  
3. äº”å±‚æµ‹è¯•ç”Ÿæˆ - å®Œæ•´æµ‹è¯•æ¶æ„è‡ªåŠ¨ç”Ÿæˆ
4. è´¨é‡è‡ªåŠ¨éªŒè¯ - è¯­æ³•ã€å¯¼å…¥ã€æ‰§è¡ŒéªŒè¯

ä½¿ç”¨æ–¹æ³•:
    python scripts/generate_test_template.py user_auth --type all --validate
    python scripts/generate_test_template.py shopping_cart --type unit --dry-run

ç¬¦åˆæ ‡å‡†:
- MASTER.mdå¼ºåˆ¶æ£€æŸ¥ç‚¹è§„èŒƒ [CHECK:DEV-009] [CHECK:TEST-001]
- docs/standards/testing-standards.mdäº”å±‚æµ‹è¯•æ¶æ„
- docs/standards/checkpoint-cards.mdéªŒè¯æµç¨‹

ä½œè€…: AI Assistant (éµå¾ªMASTERæ–‡æ¡£è§„èŒƒ)
ç‰ˆæœ¬: 2.0 (æ™ºèƒ½åˆ†æå¢å¼ºç‰ˆ)
åˆ›å»ºæ—¶é—´: 2025-09-20
"""

import sys
import os
import argparse
import ast
import inspect
import importlib.util
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))


@dataclass
class FieldInfo:
    """æ•°æ®æ¨¡å‹å­—æ®µä¿¡æ¯"""
    name: str
    column_type: str
    python_type: str
    nullable: bool
    primary_key: bool
    foreign_key: Optional[str]
    unique: bool
    default: Any
    constraints: List[str]
    
    
@dataclass  
class RelationshipInfo:
    """æ•°æ®æ¨¡å‹å…³ç³»ä¿¡æ¯"""
    name: str
    related_model: str
    relationship_type: str
    back_populates: Optional[str]
    cascade: Optional[str]
    foreign_keys: List[str]


@dataclass
class ModelInfo:
    """å®Œæ•´çš„æ•°æ®æ¨¡å‹ä¿¡æ¯"""
    name: str
    tablename: str
    fields: List[FieldInfo]
    relationships: List[RelationshipInfo]
    mixins: List[str]
    docstring: Optional[str]
    primary_keys: List[str]
    unique_constraints: List[List[str]]


class IntelligentTestGenerator:
    """æ™ºèƒ½æµ‹è¯•ç”Ÿæˆå™¨ - é›†æˆæ¨¡å‹åˆ†æå’Œæµ‹è¯•ç”Ÿæˆ [CHECK:DEV-009] [CHECK:TEST-001]"""
    
    def __init__(self):
        """åˆå§‹åŒ–ç”Ÿæˆå™¨"""
        self.project_root = Path(__file__).parent.parent
        self.test_distributions = {
            'unit': 0.70,      # 70% å•å…ƒæµ‹è¯•
            'integration': 0.20, # 20% é›†æˆæµ‹è¯•  
            'e2e': 0.06,       # 6% E2Eæµ‹è¯•
            'smoke': 0.02,     # 2% çƒŸé›¾æµ‹è¯•
            'specialized': 0.02 # 2% ä¸“é¡¹æµ‹è¯•
        }
        self.models_cache = {}
        
    def analyze_module_models(self, module_name: str) -> Dict[str, ModelInfo]:
        """æ™ºèƒ½åˆ†ææ¨¡å—ä¸­çš„æ‰€æœ‰æ•°æ®æ¨¡å‹ [CHECK:TEST-001]
        
        Args:
            module_name: æ¨¡å—åç§°ï¼Œå¦‚ 'user_auth'
            
        Returns:
            Dict[str, ModelInfo]: æ¨¡å‹åç§°åˆ°æ¨¡å‹ä¿¡æ¯çš„æ˜ å°„
            
        Raises:
            FileNotFoundError: å½“æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨æ—¶
            ImportError: å½“æ¨¡å—å¯¼å…¥å¤±è´¥æ—¶
        """
        if module_name in self.models_cache:
            return self.models_cache[module_name]
            
        print(f"ğŸ” å¼€å§‹æ™ºèƒ½åˆ†ææ¨¡å—: {module_name}")
        
        # 1. éªŒè¯æ¨¡å—æ–‡ä»¶å­˜åœ¨
        models_file = self.project_root / f"app/modules/{module_name}/models.py"
        if not models_file.exists():
            raise FileNotFoundError(f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {models_file}")
            
        # 2. ASTè¯­æ³•åˆ†æ
        ast_models = self._analyze_with_ast(models_file)
        print(f"ğŸ“‹ ASTåˆ†æå‘ç° {len(ast_models)} ä¸ªæ¨¡å‹ç±»")
        
        # 3. è¿è¡Œæ—¶åˆ†æ
        runtime_models = self._analyze_with_runtime(module_name)
        print(f"ğŸƒ è¿è¡Œæ—¶åˆ†æå‘ç° {len(runtime_models)} ä¸ªæ¨¡å‹ç±»")
        
        # 4. åˆå¹¶åˆ†æç»“æœ
        if runtime_models or ast_models:
            merged_models = self._merge_analysis_results(ast_models, runtime_models)
            print(f"âœ… åˆ†æå®Œæˆï¼Œå…±è¯†åˆ« {len(merged_models)} ä¸ªæ•°æ®æ¨¡å‹")
        else:
            print("âŒ æœªå‘ç°ä»»ä½•æ•°æ®æ¨¡å‹")
            merged_models = {}
        
        # 5. ç¼“å­˜ç»“æœ
        self.models_cache[module_name] = merged_models
        return merged_models
        
    def _analyze_with_ast(self, models_file: Path) -> Dict[str, Dict]:
        """ä½¿ç”¨ASTåˆ†ææºä»£ç ç»“æ„
        
        Args:
            models_file: æ¨¡å‹æ–‡ä»¶è·¯å¾„
            
        Returns:
            Dict[str, Dict]: ASTåˆ†æç»“æœ
        """
        try:
            with open(models_file, 'r', encoding='utf-8') as f:
                content = f.read()
                
            tree = ast.parse(content)
            models = {}
            
            for node in ast.walk(tree):
                if isinstance(node, ast.ClassDef):
                    if self._is_sqlalchemy_model_class(node):
                        model_info = self._extract_ast_model_info(node)
                        models[node.name] = model_info
                        
            return models
            
        except Exception as e:
            print(f"âš ï¸ ASTåˆ†æå¤±è´¥: {e}")
            return {}
            
    def _is_sqlalchemy_model_class(self, class_node: ast.ClassDef) -> bool:
        """æ£€æŸ¥æ˜¯å¦ä¸ºSQLAlchemyæ¨¡å‹ç±»
        
        Args:
            class_node: ASTç±»èŠ‚ç‚¹
            
        Returns:
            bool: æ˜¯å¦ä¸ºæ¨¡å‹ç±»
        """
        # æ£€æŸ¥æ˜¯å¦ç»§æ‰¿Base
        for base in class_node.bases:
            if isinstance(base, ast.Name) and base.id == 'Base':
                return True
                
        # æ£€æŸ¥æ˜¯å¦æœ‰__tablename__å±æ€§
        for item in class_node.body:
            if isinstance(item, ast.Assign):
                for target in item.targets:
                    if isinstance(target, ast.Name) and target.id == '__tablename__':
                        return True
                        
        return False
        
    def _extract_ast_model_info(self, class_node: ast.ClassDef) -> Dict:
        """ä»ASTèŠ‚ç‚¹æå–æ¨¡å‹ä¿¡æ¯
        
        Args:
            class_node: ASTç±»èŠ‚ç‚¹
            
        Returns:
            Dict: æ¨¡å‹åŸºç¡€ä¿¡æ¯
        """
        model_info = {
            'name': class_node.name,
            'tablename': None,
            'fields': [],
            'relationships': [],
            'mixins': [base.id for base in class_node.bases if isinstance(base, ast.Name)],
            'docstring': ast.get_docstring(class_node)
        }
        
        # åˆ†æç±»ä½“å†…å®¹
        for item in class_node.body:
            if isinstance(item, ast.Assign):
                self._analyze_ast_assignment(item, model_info)
                
        return model_info
        
    def _analyze_ast_assignment(self, assign_node: ast.Assign, model_info: Dict):
        """åˆ†æASTèµ‹å€¼è¯­å¥
        
        Args:
            assign_node: èµ‹å€¼èŠ‚ç‚¹
            model_info: æ¨¡å‹ä¿¡æ¯å­—å…¸
        """
        for target in assign_node.targets:
            if isinstance(target, ast.Name):
                attr_name = target.id
                
                if attr_name == '__tablename__':
                    if isinstance(assign_node.value, ast.Constant):
                        model_info['tablename'] = assign_node.value.value
                        
                elif isinstance(assign_node.value, ast.Call):
                    func_name = self._get_ast_function_name(assign_node.value.func)
                    
                    if func_name == 'Column':
                        field_info = self._analyze_ast_column(attr_name, assign_node.value)
                        model_info['fields'].append(field_info)
                        
                    elif func_name == 'relationship':
                        rel_info = self._analyze_ast_relationship(attr_name, assign_node.value)
                        model_info['relationships'].append(rel_info)
                        
    def _get_ast_function_name(self, func_node) -> str:
        """è·å–ASTå‡½æ•°åç§°
        
        Args:
            func_node: å‡½æ•°èŠ‚ç‚¹
            
        Returns:
            str: å‡½æ•°åç§°
        """
        if isinstance(func_node, ast.Name):
            return func_node.id
        elif isinstance(func_node, ast.Attribute):
            return func_node.attr
        return ''
        
    def _analyze_ast_column(self, field_name: str, call_node: ast.Call) -> Dict:
        """åˆ†æAST Columnå®šä¹‰
        
        Args:
            field_name: å­—æ®µåç§°
            call_node: è°ƒç”¨èŠ‚ç‚¹
            
        Returns:
            Dict: å­—æ®µä¿¡æ¯
        """
        field_info = {
            'name': field_name,
            'column_type': 'Unknown',
            'nullable': True,
            'primary_key': False,
            'unique': False,
            'default': None
        }
        
        # åˆ†æä½ç½®å‚æ•°ï¼ˆç±»å‹ï¼‰
        if call_node.args:
            type_arg = call_node.args[0]
            if isinstance(type_arg, ast.Name):
                field_info['column_type'] = type_arg.id
            elif isinstance(type_arg, ast.Call):
                field_info['column_type'] = self._get_ast_function_name(type_arg.func)
                
        # åˆ†æå…³é”®å­—å‚æ•°
        for keyword in call_node.keywords:
            if keyword.arg == 'nullable':
                field_info['nullable'] = self._extract_ast_boolean(keyword.value)
            elif keyword.arg == 'primary_key':
                field_info['primary_key'] = self._extract_ast_boolean(keyword.value)
            elif keyword.arg == 'unique':
                field_info['unique'] = self._extract_ast_boolean(keyword.value)
            elif keyword.arg == 'default':
                field_info['default'] = self._extract_ast_value(keyword.value)
                
        return field_info
        
    def _analyze_ast_relationship(self, rel_name: str, call_node: ast.Call) -> Dict:
        """åˆ†æAST relationshipå®šä¹‰
        
        Args:
            rel_name: å…³ç³»åç§°
            call_node: è°ƒç”¨èŠ‚ç‚¹
            
        Returns:
            Dict: å…³ç³»ä¿¡æ¯
        """
        rel_info = {
            'name': rel_name,
            'related_model': None,
            'back_populates': None,
            'cascade': None
        }
        
        # åˆ†æä½ç½®å‚æ•°ï¼ˆç›¸å…³æ¨¡å‹ï¼‰
        if call_node.args:
            model_arg = call_node.args[0]
            if isinstance(model_arg, ast.Constant):
                rel_info['related_model'] = model_arg.value
                
        # åˆ†æå…³é”®å­—å‚æ•°
        for keyword in call_node.keywords:
            if keyword.arg == 'back_populates':
                rel_info['back_populates'] = self._extract_ast_value(keyword.value)
            elif keyword.arg == 'cascade':
                rel_info['cascade'] = self._extract_ast_value(keyword.value)
                
        return rel_info
        
    def _extract_ast_boolean(self, value_node) -> bool:
        """æå–ASTå¸ƒå°”å€¼
        
        Args:
            value_node: å€¼èŠ‚ç‚¹
            
        Returns:
            bool: å¸ƒå°”å€¼
        """
        if isinstance(value_node, ast.Constant):
            return bool(value_node.value)
        elif isinstance(value_node, ast.NameConstant):  # Python < 3.8
            return bool(value_node.value)
        return False
        
    def _extract_ast_value(self, value_node) -> Any:
        """æå–ASTå€¼
        
        Args:
            value_node: å€¼èŠ‚ç‚¹
            
        Returns:
            Any: æå–çš„å€¼
        """
        if isinstance(value_node, ast.Constant):
            return value_node.value
        elif isinstance(value_node, ast.NameConstant):  # Python < 3.8
            return value_node.value
        return None
        
    def _analyze_with_runtime(self, module_name: str) -> Dict[str, Any]:
        """ä½¿ç”¨è¿è¡Œæ—¶åå°„åˆ†ææ¨¡å‹
        
        Args:
            module_name: æ¨¡å—åç§°
            
        Returns:
            Dict[str, Any]: è¿è¡Œæ—¶åˆ†æç»“æœ
        """
        try:
            # åŠ¨æ€å¯¼å…¥æ¨¡å—
            module_path = f"app.modules.{module_name}.models"
            spec = importlib.util.spec_from_file_location(
                module_path, 
                self.project_root / f"app/modules/{module_name}/models.py"
            )
            module = importlib.util.module_from_spec(spec)
            spec.loader.exec_module(module)
            
            models = {}
            
            # è·å–æ¨¡å—ä¸­çš„æ‰€æœ‰SQLAlchemyæ¨¡å‹ç±»
            for name, obj in inspect.getmembers(module, inspect.isclass):
                if self._is_sqlalchemy_model_runtime(obj):
                    models[name] = self._extract_runtime_model_info(obj)
                    
            return models
            
        except Exception as e:
            print(f"âš ï¸ è¿è¡Œæ—¶åˆ†æå¤±è´¥: {e}")
            return {}
            
    def _is_sqlalchemy_model_runtime(self, model_class) -> bool:
        """æ£€æŸ¥æ˜¯å¦ä¸ºSQLAlchemyæ¨¡å‹ç±»ï¼ˆè¿è¡Œæ—¶ï¼‰
        
        Args:
            model_class: æ¨¡å‹ç±»
            
        Returns:
            bool: æ˜¯å¦ä¸ºæ¨¡å‹ç±»
        """
        return (hasattr(model_class, '__tablename__') and 
                hasattr(model_class, '__table__'))
                
    def _extract_runtime_model_info(self, model_class) -> Dict:
        """ä»è¿è¡Œæ—¶æ¨¡å‹ç±»æå–å®Œæ•´ä¿¡æ¯
        
        Args:
            model_class: SQLAlchemyæ¨¡å‹ç±»
            
        Returns:
            Dict: å®Œæ•´çš„æ¨¡å‹ä¿¡æ¯
        """
        table = model_class.__table__
        
        model_info = {
            'name': model_class.__name__,
            'tablename': table.name,
            'fields': [],
            'relationships': [],
            'primary_keys': [col.name for col in table.primary_key.columns],
            'unique_constraints': []
        }
        
        # æå–å­—æ®µä¿¡æ¯
        for column in table.columns:
            field_info = FieldInfo(
                name=column.name,
                column_type=str(column.type),
                python_type=self._get_python_type(column.type),
                nullable=column.nullable,
                primary_key=column.primary_key,
                foreign_key=self._get_foreign_key(column),
                unique=column.unique,
                default=self._get_default_value(column),
                constraints=self._get_field_constraints(column)
            )
            model_info['fields'].append(field_info)
            
        # æå–å…³ç³»ä¿¡æ¯
        if hasattr(model_class, '__mapper__'):
            for rel_name, relationship in model_class.__mapper__.relationships.items():
                try:
                    rel_info = RelationshipInfo(
                        name=rel_name,
                        related_model=relationship.mapper.class_.__name__,
                        relationship_type=self._determine_relationship_type(relationship),
                        back_populates=relationship.back_populates,
                        cascade=str(relationship.cascade) if relationship.cascade else None,
                        foreign_keys=[str(fk.parent.name) for fk in getattr(relationship, 'foreign_keys', [])]
                    )
                    model_info['relationships'].append(rel_info)
                except Exception as e:
                    print(f"âš ï¸ å…³ç³»{rel_name}åˆ†æå¤±è´¥: {e}")
                    continue
                
        return model_info
        
    def _get_python_type(self, column_type) -> str:
        """è·å–å­—æ®µçš„Pythonç±»å‹
        
        Args:
            column_type: SQLAlchemyåˆ—ç±»å‹
            
        Returns:
            str: Pythonç±»å‹åç§°
        """
        try:
            return column_type.python_type.__name__
        except (AttributeError, NotImplementedError):
            return 'str'  # é»˜è®¤ä¸ºå­—ç¬¦ä¸²ç±»å‹
            
    def _get_foreign_key(self, column) -> Optional[str]:
        """è·å–å¤–é”®ä¿¡æ¯
        
        Args:
            column: SQLAlchemyåˆ—å¯¹è±¡
            
        Returns:
            Optional[str]: å¤–é”®ç›®æ ‡è¡¨.åˆ—åï¼Œå¦‚ 'users.id'
        """
        if column.foreign_keys:
            fk = list(column.foreign_keys)[0]
            return str(fk.target_fullname)
        return None
        
    def _get_default_value(self, column) -> Any:
        """è·å–é»˜è®¤å€¼
        
        Args:
            column: SQLAlchemyåˆ—å¯¹è±¡
            
        Returns:
            Any: é»˜è®¤å€¼
        """
        if column.default is not None:
            return column.default.arg
        return None
        
    def _get_field_constraints(self, column) -> List[str]:
        """è·å–å­—æ®µçº¦æŸä¿¡æ¯
        
        Args:
            column: SQLAlchemyåˆ—å¯¹è±¡
            
        Returns:
            List[str]: çº¦æŸåˆ—è¡¨
        """
        constraints = []
        
        if column.primary_key:
            constraints.append('PRIMARY KEY')
        if not column.nullable:
            constraints.append('NOT NULL')
        if column.unique:
            constraints.append('UNIQUE')
        if column.foreign_keys:
            constraints.append('FOREIGN KEY')
        if column.index:
            constraints.append('INDEX')
            
        return constraints
        
    def _determine_relationship_type(self, relationship) -> str:
        """ç¡®å®šå…³ç³»ç±»å‹
        
        Args:
            relationship: SQLAlchemyå…³ç³»å¯¹è±¡
            
        Returns:
            str: å…³ç³»ç±»å‹
        """
        if relationship.uselist:
            return "one-to-many" if not relationship.secondary else "many-to-many"
        else:
            return "one-to-one"
            
    def _merge_analysis_results(self, ast_models: Dict, runtime_models: Dict) -> Dict[str, ModelInfo]:
        """åˆå¹¶ASTå’Œè¿è¡Œæ—¶åˆ†æç»“æœ
        
        Args:
            ast_models: ASTåˆ†æç»“æœ
            runtime_models: è¿è¡Œæ—¶åˆ†æç»“æœ
            
        Returns:
            Dict[str, ModelInfo]: åˆå¹¶åçš„å®Œæ•´æ¨¡å‹ä¿¡æ¯
        """
        merged = {}
        
        # ä»¥è¿è¡Œæ—¶åˆ†æä¸ºä¸»ï¼ŒASTåˆ†æä½œä¸ºè¡¥å……
        for model_name, runtime_info in runtime_models.items():
            ast_info = ast_models.get(model_name, {})
            
            try:
                merged[model_name] = ModelInfo(
                    name=model_name,
                    tablename=runtime_info['tablename'],
                    fields=runtime_info['fields'],
                    relationships=runtime_info['relationships'],
                    mixins=ast_info.get('mixins', []),
                    docstring=ast_info.get('docstring'),
                    primary_keys=runtime_info.get('primary_keys', []),
                    unique_constraints=runtime_info.get('unique_constraints', [])
                )
                print(f"ğŸ”— åˆå¹¶æ¨¡å‹: {model_name} ({len(runtime_info['fields'])}å­—æ®µ, {len(runtime_info['relationships'])}å…³ç³»)")
            except Exception as e:
                print(f"âš ï¸ æ¨¡å‹{model_name}åˆå¹¶å¤±è´¥: {e}")
                continue
            
        return merged
            
    def generate_tests(self, module_name: str, test_type: str = 'all', 
                      dry_run: bool = False, validate: bool = True) -> Dict[str, str]:
        """ç”Ÿæˆæµ‹è¯•æ–‡ä»¶
        
        Args:
            module_name: æ¨¡å—åç§°
            test_type: æµ‹è¯•ç±»å‹ ('all', 'unit', 'integration', 'e2e', 'smoke', 'specialized')
            dry_run: æ˜¯å¦ä¸ºè¯•è¿è¡Œï¼ˆä¸å†™å…¥æ–‡ä»¶ï¼‰
            validate: æ˜¯å¦éªŒè¯ç”Ÿæˆçš„ä»£ç 
            
        Returns:
            Dict[str, str]: æ–‡ä»¶è·¯å¾„åˆ°å†…å®¹çš„æ˜ å°„
        """
        # 1. åˆ†ææ¨¡å‹
        models = self.analyze_module_models(module_name)
        
        # 2. ç”Ÿæˆæµ‹è¯•æ–‡ä»¶
        generated_files = {}
        
        if test_type in ['all', 'unit']:
            unit_files = self._generate_unit_tests(module_name, models)
            generated_files.update(unit_files)
            
        if test_type in ['all', 'integration']:
            integration_files = self._generate_integration_tests(module_name, models)
            generated_files.update(integration_files)
            
        if test_type in ['all', 'e2e']:
            e2e_files = self._generate_e2e_tests(module_name, models)
            generated_files.update(e2e_files)
            
        if test_type in ['all', 'smoke']:
            smoke_files = self._generate_smoke_tests(module_name, models)
            generated_files.update(smoke_files)
            
        if test_type in ['all', 'specialized']:
            specialized_files = self._generate_specialized_tests(module_name, models)
            generated_files.update(specialized_files)
            
        # 3. å†™å…¥æ–‡ä»¶ï¼ˆå¦‚æœä¸æ˜¯è¯•è¿è¡Œï¼‰
        if not dry_run:
            self._write_test_files(generated_files)
            
        # 4. éªŒè¯ç”Ÿæˆçš„ä»£ç ï¼ˆå¦‚æœéœ€è¦ï¼‰
        if validate and not dry_run:
            self._validate_generated_tests(generated_files)
            
        print(f"âœ… ç”Ÿæˆå®Œæˆï¼Œå…± {len(generated_files)} ä¸ªæµ‹è¯•æ–‡ä»¶")
        return generated_files
        
    def _generate_unit_tests(self, module_name: str, models: Dict[str, ModelInfo]) -> Dict[str, str]:
        """ç”Ÿæˆå•å…ƒæµ‹è¯• (70%)"""
        files = {}
        
        # 1. æ¨¡å‹æµ‹è¯•æ–‡ä»¶
        model_tests = self._generate_model_tests(module_name, models)
        files[f'tests/unit/test_models/test_{module_name}_models.py'] = model_tests
        
        # 2. æœåŠ¡å±‚æµ‹è¯•æ–‡ä»¶  
        service_tests = self._generate_service_tests(module_name, models)
        files[f'tests/unit/test_services/test_{module_name}_service.py'] = service_tests
        
        # 3. ä¸šåŠ¡æµç¨‹æµ‹è¯•æ–‡ä»¶
        workflow_tests = self._generate_workflow_tests(module_name, models)
        files[f'tests/unit/test_{module_name}_workflow.py'] = workflow_tests
        
        return files
        
    def _generate_model_tests(self, module_name: str, models: Dict[str, ModelInfo]) -> str:
        """ç”Ÿæˆæ¨¡å‹æµ‹è¯•ä»£ç """
        test_classes = []
        
        # ä¸ºæ¯ä¸ªæ¨¡å‹ç”Ÿæˆæµ‹è¯•ç±»
        for model_name, model_info in models.items():
            test_class = self._generate_single_model_test(model_info)
            test_classes.append(test_class)
            
        imports = f'''"""
{module_name.title()} æ¨¡å—æ•°æ®æ¨¡å‹æµ‹è¯•

æµ‹è¯•ç±»å‹: å•å…ƒæµ‹è¯• - æ¨¡å‹å­—æ®µã€çº¦æŸã€å…³ç³»éªŒè¯
æ•°æ®ç­–ç•¥: Mockå¯¹è±¡ï¼Œæ— æ•°æ®åº“ä¾èµ–
ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

ç¬¦åˆæ ‡å‡†: [CHECK:TEST-001] [CHECK:DEV-009]
"""

import pytest
from unittest.mock import Mock, patch, MagicMock
from datetime import datetime, date
from decimal import Decimal

# æµ‹è¯•å·¥å‚å¯¼å…¥
from tests.factories.test_data_factory import StandardTestDataFactory

'''

        return imports + '\n\n'.join(test_classes)
        
    def _generate_single_model_test(self, model_info: ModelInfo) -> str:
        """ä¸ºå•ä¸ªæ¨¡å‹ç”Ÿæˆæµ‹è¯•ç±»"""
        model_name = model_info.name
        
        test_methods = []
        
        # 1. å­—æ®µéªŒè¯æµ‹è¯•
        field_tests = self._generate_field_tests(model_info)
        test_methods.extend(field_tests)
        
        # 2. çº¦æŸéªŒè¯æµ‹è¯•
        constraint_tests = self._generate_constraint_tests(model_info)
        test_methods.extend(constraint_tests)
        
        # 3. å…³ç³»éªŒè¯æµ‹è¯•
        if model_info.relationships:
            relationship_tests = self._generate_relationship_tests(model_info)
            test_methods.extend(relationship_tests)
            
        class_code = f'''
class Test{model_name}Model:
    """{model_name}æ¨¡å‹æµ‹è¯•ç±»"""
    
    def setup_method(self):
        """æµ‹è¯•å‡†å¤‡"""
        self.mock_{model_name.lower()} = Mock()
        
{chr(10).join(test_methods)}
'''
        
        return class_code
        
    def _generate_field_tests(self, model_info: ModelInfo) -> List[str]:
        """ç”Ÿæˆå­—æ®µæµ‹è¯•æ–¹æ³•"""
        tests = []
        
        for field in model_info.fields:
            test_method = f'''    def test_{field.name}_field_validation(self):
        """æµ‹è¯•{field.name}å­—æ®µéªŒè¯"""
        mock_data = {{{repr(field.name)}: self._get_valid_value_for_type("{field.python_type}")}}
        
        # éªŒè¯å­—æ®µç±»å‹å’Œçº¦æŸ
        assert {repr(field.name)} in mock_data
        assert isinstance(mock_data[{repr(field.name)}], ({field.python_type}, type(None)))'''
        
            tests.append(test_method)
            
        return tests
        
    def _generate_constraint_tests(self, model_info: ModelInfo) -> List[str]:
        """ç”Ÿæˆçº¦æŸæµ‹è¯•æ–¹æ³•"""
        tests = []
        
        # ä¸»é”®æµ‹è¯•
        if model_info.primary_keys:
            pk_test = f'''    def test_primary_key_constraints(self):
        """æµ‹è¯•ä¸»é”®çº¦æŸ"""
        primary_keys = {model_info.primary_keys}
        
        # éªŒè¯ä¸»é”®å­—æ®µå­˜åœ¨
        for pk in primary_keys:
            assert hasattr(self.mock_{model_info.name.lower()}, pk)'''
            tests.append(pk_test)
            
        # å”¯ä¸€çº¦æŸæµ‹è¯•
        unique_fields = [f.name for f in model_info.fields if f.unique]
        if unique_fields:
            unique_test = f'''    def test_unique_constraints(self):
        """æµ‹è¯•å”¯ä¸€çº¦æŸ"""
        unique_fields = {unique_fields}
        
        # éªŒè¯å”¯ä¸€å­—æ®µ
        for field in unique_fields:
            assert hasattr(self.mock_{model_info.name.lower()}, field)'''
            tests.append(unique_test)
            
        return tests
        
    def _generate_relationship_tests(self, model_info: ModelInfo) -> List[str]:
        """ç”Ÿæˆå…³ç³»æµ‹è¯•æ–¹æ³•"""
        tests = []
        
        for rel in model_info.relationships:
            rel_test = f'''    def test_{rel.name}_relationship(self):
        """æµ‹è¯•{rel.name}å…³ç³»"""
        # éªŒè¯{rel.relationship_type}å…³ç³»åˆ°{rel.related_model}
        mock_relation = Mock()
        self.mock_{model_info.name.lower()}.{rel.name} = mock_relation
        
        assert hasattr(self.mock_{model_info.name.lower()}, "{rel.name}")'''
            tests.append(rel_test)
            
        return tests
        
    def _generate_service_tests(self, module_name: str, models: Dict[str, ModelInfo]) -> str:
        """ç”ŸæˆæœåŠ¡å±‚æµ‹è¯•"""
        return f'''"""
{module_name.title()} æœåŠ¡å±‚æµ‹è¯•

æµ‹è¯•ç±»å‹: å•å…ƒæµ‹è¯• - æœåŠ¡å±‚ä¸šåŠ¡é€»è¾‘
æ•°æ®ç­–ç•¥: SQLiteå†…å­˜æ•°æ®åº“
ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

ç¬¦åˆæ ‡å‡†: [CHECK:TEST-001]
"""

import pytest
from sqlalchemy.orm import Session

# æµ‹è¯•ä¾èµ–
from tests.conftest import unit_test_db
from tests.factories.test_data_factory import StandardTestDataFactory

# è¢«æµ‹æœåŠ¡
try:
    from app.modules.{module_name}.service import {module_name.title()}Service
except ImportError:
    {module_name.title()}Service = Mock()  # æœåŠ¡ä¸å­˜åœ¨æ—¶ä½¿ç”¨Mock


class Test{module_name.title()}Service:
    """æœåŠ¡å±‚æµ‹è¯•ç±»"""
    
    def setup_method(self):
        """æµ‹è¯•å‡†å¤‡"""
        self.test_data_factory = StandardTestDataFactory()
        
    def test_service_initialization(self, unit_test_db: Session):
        """æµ‹è¯•æœåŠ¡åˆå§‹åŒ–"""
        service = {module_name.title()}Service(unit_test_db)
        assert service is not None
        
    def test_basic_crud_operations(self, unit_test_db: Session):
        """æµ‹è¯•åŸºç¡€CRUDæ“ä½œ"""
        service = {module_name.title()}Service(unit_test_db)
        
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        test_data = self.test_data_factory.create_sample_data()
        
        # æµ‹è¯•åˆ›å»ºã€è¯»å–ã€æ›´æ–°ã€åˆ é™¤
        # è¿™é‡Œéœ€è¦æ ¹æ®å…·ä½“çš„æœåŠ¡æ–¹æ³•è¿›è¡Œå®ç°
        assert True  # å ä½ç¬¦ï¼Œéœ€è¦æ ¹æ®å®é™…æœåŠ¡APIè°ƒæ•´
'''
        
    def _generate_workflow_tests(self, module_name: str, models: Dict[str, ModelInfo]) -> str:
        """ç”Ÿæˆä¸šåŠ¡æµç¨‹æµ‹è¯•"""
        return f'''"""
{module_name.title()} ä¸šåŠ¡æµç¨‹æµ‹è¯•

æµ‹è¯•ç±»å‹: å•å…ƒæµ‹è¯• - å®Œæ•´ä¸šåŠ¡æµç¨‹
æ•°æ®ç­–ç•¥: SQLiteå†…å­˜æ•°æ®åº“
ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

ç¬¦åˆæ ‡å‡†: [CHECK:TEST-001]
"""

import pytest
from sqlalchemy.orm import Session

# æµ‹è¯•ä¾èµ–
from tests.conftest import unit_test_db
from tests.factories.test_data_factory import StandardTestDataFactory


class Test{module_name.title()}Workflow:
    """ä¸šåŠ¡æµç¨‹æµ‹è¯•ç±»"""
    
    def setup_method(self):
        """æµ‹è¯•å‡†å¤‡"""
        self.test_data_factory = StandardTestDataFactory()
        
    def test_complete_{module_name}_workflow(self, unit_test_db: Session):
        """æµ‹è¯•å®Œæ•´{module_name}ä¸šåŠ¡æµç¨‹"""
        # è¿™é‡Œéœ€è¦æ ¹æ®å…·ä½“çš„ä¸šåŠ¡æµç¨‹è¿›è¡Œå®ç°
        # é€šå¸¸åŒ…æ‹¬ï¼šåˆ›å»ºâ†’éªŒè¯â†’æ›´æ–°â†’æŸ¥è¯¢â†’åˆ é™¤çš„å®Œæ•´æµç¨‹
        assert True  # å ä½ç¬¦ï¼Œéœ€è¦æ ¹æ®å®é™…ä¸šåŠ¡æµç¨‹è°ƒæ•´
'''

    def _generate_integration_tests(self, module_name: str, models: Dict[str, ModelInfo]) -> Dict[str, str]:
        """ç”Ÿæˆé›†æˆæµ‹è¯• (20%)"""
        return {}  # å ä½ç¬¦ï¼Œéœ€è¦å®ç°
        
    def _generate_e2e_tests(self, module_name: str, models: Dict[str, ModelInfo]) -> Dict[str, str]:
        """ç”ŸæˆE2Eæµ‹è¯• (6%)"""
        return {}  # å ä½ç¬¦ï¼Œéœ€è¦å®ç°
        
    def _generate_smoke_tests(self, module_name: str, models: Dict[str, ModelInfo]) -> Dict[str, str]:
        """ç”ŸæˆçƒŸé›¾æµ‹è¯• (2%)"""
        return {}  # å ä½ç¬¦ï¼Œéœ€è¦å®ç°
        
    def _generate_specialized_tests(self, module_name: str, models: Dict[str, ModelInfo]) -> Dict[str, str]:
        """ç”Ÿæˆä¸“é¡¹æµ‹è¯• (2%)"""
        return {}  # å ä½ç¬¦ï¼Œéœ€è¦å®ç°
        
    def _write_test_files(self, files: Dict[str, str]):
        """å†™å…¥æµ‹è¯•æ–‡ä»¶åˆ°ç£ç›˜"""
        for file_path, content in files.items():
            full_path = self.project_root / file_path
            full_path.parent.mkdir(parents=True, exist_ok=True)
            
            with open(full_path, 'w', encoding='utf-8') as f:
                f.write(content)
                
            print(f"ğŸ“ ç”Ÿæˆæ–‡ä»¶: {file_path}")
            
    def _validate_generated_tests(self, files: Dict[str, str]):
        """éªŒè¯ç”Ÿæˆçš„æµ‹è¯•ä»£ç """
        print("ğŸ” å¼€å§‹éªŒè¯ç”Ÿæˆçš„æµ‹è¯•ä»£ç ...")
        
        for file_path, content in files.items():
            try:
                # è¯­æ³•æ£€æŸ¥
                compile(content, file_path, 'exec')
                print(f"âœ… è¯­æ³•æ£€æŸ¥é€šè¿‡: {file_path}")
            except SyntaxError as e:
                print(f"âŒ è¯­æ³•é”™è¯¯ {file_path}: {e}")
                
        print("âœ… ä»£ç éªŒè¯å®Œæˆ")


def main():
    """ä¸»ç¨‹åºå…¥å£ [CHECK:DEV-009]"""
    parser = argparse.ArgumentParser(
        description='æ™ºèƒ½äº”å±‚æ¶æ„æµ‹è¯•ç”Ÿæˆå™¨ v2.0',
        epilog='ç¤ºä¾‹: python scripts/generate_test_template.py user_auth --type all --validate'
    )
    
    parser.add_argument('module_name', help='æ¨¡å—åç§° (å¦‚: user_auth, shopping_cart)')
    parser.add_argument('--type', choices=['all', 'unit', 'integration', 'e2e', 'smoke', 'specialized'], 
                       default='all', help='ç”Ÿæˆçš„æµ‹è¯•ç±»å‹')
    parser.add_argument('--dry-run', action='store_true', help='è¯•è¿è¡Œæ¨¡å¼ï¼ˆä¸å†™å…¥æ–‡ä»¶ï¼‰')
    parser.add_argument('--validate', action='store_true', default=True, help='éªŒè¯ç”Ÿæˆçš„ä»£ç ')
    parser.add_argument('--detailed', action='store_true', help='æ˜¾ç¤ºè¯¦ç»†çš„åˆ†æä¿¡æ¯')
    
    args = parser.parse_args()
    
    try:
        generator = IntelligentTestGenerator()
        
        if args.detailed:
            # æ˜¾ç¤ºè¯¦ç»†åˆ†æä¿¡æ¯
            models = generator.analyze_module_models(args.module_name)
            for model_name, model_info in models.items():
                print(f"\nğŸ“Š {model_name} æ¨¡å‹:")
                print(f"   è¡¨å: {model_info.tablename}")
                print(f"   å­—æ®µ: {len(model_info.fields)}ä¸ª")
                print(f"   å…³ç³»: {len(model_info.relationships)}ä¸ª")
                print(f"   æ··å…¥: {', '.join(model_info.mixins) if model_info.mixins else 'æ— '}")
        else:
            # ç”Ÿæˆæµ‹è¯•
            generated_files = generator.generate_tests(
                args.module_name, 
                args.type, 
                args.dry_run, 
                args.validate
            )
            
            if args.dry_run:
                print("\nğŸ” è¯•è¿è¡Œç»“æœ:")
                for file_path in generated_files.keys():
                    print(f"   å°†ç”Ÿæˆ: {file_path}")
                    
    except Exception as e:
        print(f"âŒ æ‰§è¡Œå¤±è´¥: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()